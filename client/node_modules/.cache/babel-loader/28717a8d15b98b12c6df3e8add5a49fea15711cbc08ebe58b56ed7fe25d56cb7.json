{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.attemptInRepetitionRecovery = exports.Recoverable = exports.InRuleRecoveryException = exports.IN_RULE_RECOVERY_EXCEPTION = exports.EOF_FOLLOW_KEY = void 0;\nvar tokens_public_1 = require(\"../../../scan/tokens_public\");\nvar utils_1 = require(\"@chevrotain/utils\");\nvar exceptions_public_1 = require(\"../../exceptions_public\");\nvar constants_1 = require(\"../../constants\");\nvar parser_1 = require(\"../parser\");\nexports.EOF_FOLLOW_KEY = {};\nexports.IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nfunction InRuleRecoveryException(message) {\n  this.name = exports.IN_RULE_RECOVERY_EXCEPTION;\n  this.message = message;\n}\nexports.InRuleRecoveryException = InRuleRecoveryException;\nInRuleRecoveryException.prototype = Error.prototype;\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nvar Recoverable = /** @class */function () {\n  function Recoverable() {}\n  Recoverable.prototype.initRecoverable = function (config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = utils_1.has(config, \"recoveryEnabled\") ? config.recoveryEnabled : parser_1.DEFAULT_PARSER_CONFIG.recoveryEnabled;\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  };\n  Recoverable.prototype.getTokenToInsert = function (tokType) {\n    var tokToInsert = tokens_public_1.createTokenInstance(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  };\n  Recoverable.prototype.canTokenTypeBeInsertedInRecovery = function (tokType) {\n    return true;\n  };\n  Recoverable.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    var _this = this;\n    // TODO: can the resyncTokenType be cached?\n    var reSyncTokType = this.findReSyncTokenType();\n    var savedLexerState = this.exportLexerState();\n    var resyncedTokens = [];\n    var passedResyncPoint = false;\n    var nextTokenWithoutResync = this.LA(1);\n    var currToken = this.LA(1);\n    var generateErrorMessage = function () {\n      var previousToken = _this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      var msg = _this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: _this.getCurrRuleFullName()\n      });\n      var error = new exceptions_public_1.MismatchedTokenException(msg, nextTokenWithoutResync, _this.LA(0));\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = utils_1.dropRight(resyncedTokens);\n      _this.SAVE_ERROR(error);\n    };\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  };\n  Recoverable.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n    // arguments to try and perform resync into the next iteration of the many are missing\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n      return false;\n    }\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n    return true;\n  };\n  // Error Recovery functionality\n  Recoverable.prototype.getFollowsForInRuleRecovery = function (tokType, tokIdxInRule) {\n    var grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    var follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  };\n  Recoverable.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      var tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      var nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  };\n  Recoverable.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n    var _this = this;\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n    // must know the possible following tokens to perform single token insertion\n    if (utils_1.isEmpty(follows)) {\n      return false;\n    }\n    var mismatchedTok = this.LA(1);\n    var isMisMatchedTokInFollows = utils_1.find(follows, function (possibleFollowsTokType) {\n      return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== undefined;\n    return isMisMatchedTokInFollows;\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n    var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  };\n  Recoverable.prototype.isInCurrentRuleReSyncSet = function (tokenTypeIdx) {\n    var followKey = this.getCurrFollowKey();\n    var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return utils_1.contains(currentRuleReSyncSet, tokenTypeIdx);\n  };\n  Recoverable.prototype.findReSyncTokenType = function () {\n    var allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    var nextToken = this.LA(1);\n    var k = 2;\n    while (true) {\n      var nextTokenType = nextToken.tokenType;\n      if (utils_1.contains(allPossibleReSyncTokTypes, nextTokenType)) {\n        return nextTokenType;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  };\n  Recoverable.prototype.getCurrFollowKey = function () {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return exports.EOF_FOLLOW_KEY;\n    }\n    var currRuleShortName = this.getLastExplicitRuleShortName();\n    var currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    var prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  };\n  Recoverable.prototype.buildFullFollowKeyStack = function () {\n    var _this = this;\n    var explicitRuleStack = this.RULE_STACK;\n    var explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return utils_1.map(explicitRuleStack, function (ruleName, idx) {\n      if (idx === 0) {\n        return exports.EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: _this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: _this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  };\n  Recoverable.prototype.flattenFollowSet = function () {\n    var _this = this;\n    var followStack = utils_1.map(this.buildFullFollowKeyStack(), function (currKey) {\n      return _this.getFollowSetFromFollowKey(currKey);\n    });\n    return utils_1.flatten(followStack);\n  };\n  Recoverable.prototype.getFollowSetFromFollowKey = function (followKey) {\n    if (followKey === exports.EOF_FOLLOW_KEY) {\n      return [tokens_public_1.EOF];\n    }\n    var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  };\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  Recoverable.prototype.addToResyncTokens = function (token, resyncTokens) {\n    if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  };\n  Recoverable.prototype.reSyncTo = function (tokType) {\n    var resyncedTokens = [];\n    var nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return utils_1.dropRight(resyncedTokens);\n  };\n  Recoverable.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  };\n  Recoverable.prototype.getCurrentGrammarPath = function (tokType, tokIdxInRule) {\n    var pathRuleStack = this.getHumanReadableRuleStack();\n    var pathOccurrenceStack = utils_1.cloneArr(this.RULE_OCCURRENCE_STACK);\n    var grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  };\n  Recoverable.prototype.getHumanReadableRuleStack = function () {\n    var _this = this;\n    return utils_1.map(this.RULE_STACK, function (currShortName) {\n      return _this.shortRuleNameToFullName(currShortName);\n    });\n  };\n  return Recoverable;\n}();\nexports.Recoverable = Recoverable;\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  var firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    var currRuleName = this.getCurrRuleFullName();\n    var ruleGrammar = this.getGAstProductions()[currRuleName];\n    var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n  var expectTokAfterLastMatch = firstAfterRepInfo.token;\n  var nextTokIdx = firstAfterRepInfo.occurrence;\n  var isEndOfRule = firstAfterRepInfo.isEndOfRule;\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === undefined) {\n    expectTokAfterLastMatch = tokens_public_1.EOF;\n    nextTokIdx = 1;\n  }\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\nexports.attemptInRepetitionRecovery = attemptInRepetitionRecovery;","map":{"version":3,"names":["tokens_public_1","require","utils_1","exceptions_public_1","constants_1","parser_1","exports","EOF_FOLLOW_KEY","IN_RULE_RECOVERY_EXCEPTION","InRuleRecoveryException","message","name","prototype","Error","Recoverable","initRecoverable","config","firstAfterRepMap","resyncFollows","recoveryEnabled","has","DEFAULT_PARSER_CONFIG","attemptInRepetitionRecovery","getTokenToInsert","tokType","tokToInsert","createTokenInstance","NaN","isInsertedInRecovery","canTokenTypeBeInsertedInRecovery","tryInRepetitionRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","_this","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","LA","currToken","generateErrorMessage","previousToken","msg","errorMessageProvider","buildMismatchTokenMessage","expected","actual","previous","ruleName","getCurrRuleFullName","error","MismatchedTokenException","dropRight","SAVE_ERROR","tokenMatcher","call","apply","SKIP_TOKEN","addToResyncTokens","importLexerState","shouldInRepetitionRecoveryBeTried","expectTokAfterLastMatch","nextTokIdx","notStuck","undefined","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","follows","getNextPossibleTokenTypes","tryInRuleRecovery","canRecoverWithSingleTokenInsertion","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","expectedToken","isEmpty","mismatchedTok","isMisMatchedTokInFollows","find","possibleFollowsTokType","isNextTokenWhatIsExpected","isInCurrentRuleReSyncSet","tokenTypeIdx","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","contains","allPossibleReSyncTokTypes","flattenFollowSet","nextToken","k","nextTokenType","tokenType","RULE_STACK","length","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","buildFullFollowKeyStack","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","map","idx","followStack","currKey","flatten","EOF","followName","IN","token","resyncTokens","push","reSyncTo","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","getHumanReadableRuleStack","pathOccurrenceStack","cloneArr","ruleStack","occurrenceStack","lastTok","lastTokOccurrence","currShortName","key","getKeyForAutomaticLookahead","firstAfterRepInfo","currRuleName","ruleGrammar","getGAstProductions","walker","startWalking","occurrence","isEndOfRule"],"sources":["C:\\Users\\Work\\node_modules\\chevrotain\\src\\parse\\parser\\traits\\recoverable.ts"],"sourcesContent":["import { createTokenInstance, EOF } from \"../../../scan/tokens_public\"\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition\n} from \"../../grammar/interpreter\"\nimport {\n  cloneArr,\n  contains,\n  dropRight,\n  find,\n  flatten,\n  has,\n  isEmpty,\n  map\n} from \"@chevrotain/utils\"\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType\n} from \"@chevrotain/types\"\nimport { MismatchedTokenException } from \"../../exceptions_public\"\nimport { IN } from \"../../constants\"\nimport { MixedInParser } from \"./parser_traits\"\nimport { DEFAULT_PARSER_CONFIG } from \"../parser\"\n\nexport const EOF_FOLLOW_KEY: any = {}\n\nexport interface IFollowKey {\n  ruleName: string\n  idxInCallingRule: number\n  inRule: string\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\"\n\nexport function InRuleRecoveryException(message: string) {\n  this.name = IN_RULE_RECOVERY_EXCEPTION\n  this.message = message\n}\n\nInRuleRecoveryException.prototype = Error.prototype\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>\n  resyncFollows: Record<string, TokenType[]>\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {}\n    this.resyncFollows = {}\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? config.recoveryEnabled\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN\n    )\n    tokToInsert.isInsertedInRecovery = true\n    return tokToInsert\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType) {\n    return true\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType()\n    const savedLexerState = this.exportLexerState()\n    const resyncedTokens = []\n    let passedResyncPoint = false\n\n    const nextTokenWithoutResync = this.LA(1)\n    let currToken = this.LA(1)\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0)\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      })\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0)\n      )\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens)\n      this.SAVE_ERROR(error)\n    }\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage()\n        return // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage()\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs)\n        return // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true\n      } else {\n        currToken = this.SKIP_TOKEN()\n        this.addToResyncTokens(currToken, resyncedTokens)\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState)\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false\n    }\n\n    // arguments to try and perform resync into the next iteration of the many are missing\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n      return false\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx)\n      )\n    ) {\n      return false\n    }\n\n    return true\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule)\n    const follows = this.getNextPossibleTokenTypes(grammarPath)\n    return follows\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType)\n      return tokToInsert\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN()\n      this.consumeToken()\n      return nextTok\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\")\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    )\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false\n    }\n\n    const mismatchedTok = this.LA(1)\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType)\n      }) !== undefined\n\n    return isMisMatchedTokInFollows\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType\n  ): boolean {\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType\n    )\n    return isNextTokenWhatIsExpected\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType\n  ): boolean {\n    const followKey = this.getCurrFollowKey()\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey)\n    return contains(currentRuleReSyncSet, tokenTypeIdx)\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet()\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1)\n    let k = 2\n    while (true) {\n      const nextTokenType: any = nextToken.tokenType\n      if (contains(allPossibleReSyncTokTypes, nextTokenType)) {\n        return nextTokenType\n      }\n      nextToken = this.LA(k)\n      k++\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName()\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex()\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName()\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    }\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      }\n    })\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey)\n    })\n    return <any>flatten(followStack)\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF]\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule\n\n    return this.resyncFollows[followName]\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[]\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token)\n    }\n    return resyncTokens\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens = []\n    let nextTok = this.LA(1)\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN()\n      this.addToResyncTokens(nextTok, resyncedTokens)\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens)\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack()\n    const pathOccurrenceStack: number[] = cloneArr(this.RULE_OCCURRENCE_STACK)\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    }\n\n    return grammarPath\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName)\n    )\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean\n) {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence)\n  let firstAfterRepInfo = this.firstAfterRepMap[key]\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName()\n    const ruleGrammar = this.getGAstProductions()[currRuleName]\n    const walker: AbstractNextTerminalAfterProductionWalker = new nextToksWalker(\n      ruleGrammar,\n      prodOccurrence\n    )\n    firstAfterRepInfo = walker.startWalking()\n    this.firstAfterRepMap[key] = firstAfterRepInfo\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token\n  let nextTokIdx = firstAfterRepInfo.occurrence\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF\n    nextTokIdx = 1\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch\n    )\n  }\n}\n"],"mappings":";;;;;;AAAA,IAAAA,eAAA,GAAAC,OAAA;AAKA,IAAAC,OAAA,GAAAD,OAAA;AAgBA,IAAAE,mBAAA,GAAAF,OAAA;AACA,IAAAG,WAAA,GAAAH,OAAA;AAEA,IAAAI,QAAA,GAAAJ,OAAA;AAEaK,OAAA,CAAAC,cAAc,GAAQ,EAAE;AAQxBD,OAAA,CAAAE,0BAA0B,GAAG,yBAAyB;AAEnE,SAAgBC,uBAAuBA,CAACC,OAAe;EACrD,IAAI,CAACC,IAAI,GAAGL,OAAA,CAAAE,0BAA0B;EACtC,IAAI,CAACE,OAAO,GAAGA,OAAO;AACxB;AAHAJ,OAAA,CAAAG,uBAAA,GAAAA,uBAAA;AAKAA,uBAAuB,CAACG,SAAS,GAAGC,KAAK,CAACD,SAAS;AAEnD;;;AAGA,IAAAE,WAAA;EAAA,SAAAA,YAAA,GAmWA;EA9VEA,WAAA,CAAAF,SAAA,CAAAG,eAAe,GAAf,UAAgBC,MAAqB;IACnC,IAAI,CAACC,gBAAgB,GAAG,EAAE;IAC1B,IAAI,CAACC,aAAa,GAAG,EAAE;IAEvB,IAAI,CAACC,eAAe,GAAGjB,OAAA,CAAAkB,GAAG,CAACJ,MAAM,EAAE,iBAAiB,CAAC,GACjDA,MAAM,CAACG,eAAe,GACtBd,QAAA,CAAAgB,qBAAqB,CAACF,eAAe;IAEzC;IACA;IACA;IACA,IAAI,IAAI,CAACA,eAAe,EAAE;MACxB,IAAI,CAACG,2BAA2B,GAAGA,2BAA2B;;EAElE,CAAC;EAEMR,WAAA,CAAAF,SAAA,CAAAW,gBAAgB,GAAvB,UAAwBC,OAAkB;IACxC,IAAMC,WAAW,GAAGzB,eAAA,CAAA0B,mBAAmB,CACrCF,OAAO,EACP,EAAE,EACFG,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,CACJ;IACDF,WAAW,CAACG,oBAAoB,GAAG,IAAI;IACvC,OAAOH,WAAW;EACpB,CAAC;EAEMX,WAAA,CAAAF,SAAA,CAAAiB,gCAAgC,GAAvC,UAAwCL,OAAkB;IACxD,OAAO,IAAI;EACb,CAAC;EAEDV,WAAA,CAAAF,SAAA,CAAAkB,uBAAuB,GAAvB,UAEEC,WAAqB,EACrBC,eAAsB,EACtBC,aAA4B,EAC5BC,eAA0B;IAL5B,IAAAC,KAAA;IAOE;IACA,IAAMC,aAAa,GAAG,IAAI,CAACC,mBAAmB,EAAE;IAChD,IAAMC,eAAe,GAAG,IAAI,CAACC,gBAAgB,EAAE;IAC/C,IAAMC,cAAc,GAAG,EAAE;IACzB,IAAIC,iBAAiB,GAAG,KAAK;IAE7B,IAAMC,sBAAsB,GAAG,IAAI,CAACC,EAAE,CAAC,CAAC,CAAC;IACzC,IAAIC,SAAS,GAAG,IAAI,CAACD,EAAE,CAAC,CAAC,CAAC;IAE1B,IAAME,oBAAoB,GAAG,SAAAA,CAAA;MAC3B,IAAMC,aAAa,GAAGX,KAAI,CAACQ,EAAE,CAAC,CAAC,CAAC;MAChC;MACA;MACA,IAAMI,GAAG,GAAGZ,KAAI,CAACa,oBAAoB,CAACC,yBAAyB,CAAC;QAC9DC,QAAQ,EAAEhB,eAAe;QACzBiB,MAAM,EAAET,sBAAsB;QAC9BU,QAAQ,EAAEN,aAAa;QACvBO,QAAQ,EAAElB,KAAI,CAACmB,mBAAmB;OACnC,CAAC;MACF,IAAMC,KAAK,GAAG,IAAIpD,mBAAA,CAAAqD,wBAAwB,CACxCT,GAAG,EACHL,sBAAsB,EACtBP,KAAI,CAACQ,EAAE,CAAC,CAAC,CAAC,CACX;MACD;MACAY,KAAK,CAACf,cAAc,GAAGtC,OAAA,CAAAuD,SAAS,CAACjB,cAAc,CAAC;MAChDL,KAAI,CAACuB,UAAU,CAACH,KAAK,CAAC;IACxB,CAAC;IAED,OAAO,CAACd,iBAAiB,EAAE;MACzB;MACA,IAAI,IAAI,CAACkB,YAAY,CAACf,SAAS,EAAEV,eAAe,CAAC,EAAE;QACjDW,oBAAoB,EAAE;QACtB,OAAM,CAAC;OACR,MAAM,IAAIZ,aAAa,CAAC2B,IAAI,CAAC,IAAI,CAAC,EAAE;QACnC;QACAf,oBAAoB,EAAE;QACtB;QACAd,WAAW,CAAC8B,KAAK,CAAC,IAAI,EAAE7B,eAAe,CAAC;QACxC,OAAM,CAAC;OACR,MAAM,IAAI,IAAI,CAAC2B,YAAY,CAACf,SAAS,EAAER,aAAa,CAAC,EAAE;QACtDK,iBAAiB,GAAG,IAAI;OACzB,MAAM;QACLG,SAAS,GAAG,IAAI,CAACkB,UAAU,EAAE;QAC7B,IAAI,CAACC,iBAAiB,CAACnB,SAAS,EAAEJ,cAAc,CAAC;;;IAIrD;IACA;IACA;IACA,IAAI,CAACwB,gBAAgB,CAAC1B,eAAe,CAAC;EACxC,CAAC;EAEDxB,WAAA,CAAAF,SAAA,CAAAqD,iCAAiC,GAAjC,UAEEC,uBAAkC,EAClCC,UAAkB,EAClBC,QAA6B;IAE7B;IACA;IACA,IAAIA,QAAQ,KAAK,KAAK,EAAE;MACtB,OAAO,KAAK;;IAGd;IACA,IAAIF,uBAAuB,KAAKG,SAAS,IAAIF,UAAU,KAAKE,SAAS,EAAE;MACrE,OAAO,KAAK;;IAGd;IACA,IAAI,IAAI,CAACV,YAAY,CAAC,IAAI,CAAChB,EAAE,CAAC,CAAC,CAAC,EAAEuB,uBAAuB,CAAC,EAAE;MAC1D,OAAO,KAAK;;IAGd;IACA;IACA,IAAI,IAAI,CAACI,cAAc,EAAE,EAAE;MACzB,OAAO,KAAK;;IAGd;IACA;IACA;IACA,IACE,IAAI,CAACC,wBAAwB,CAC3BL,uBAAuB,EACvB,IAAI,CAACM,2BAA2B,CAACN,uBAAuB,EAAEC,UAAU,CAAC,CACtE,EACD;MACA,OAAO,KAAK;;IAGd,OAAO,IAAI;EACb,CAAC;EAED;EACArD,WAAA,CAAAF,SAAA,CAAA4D,2BAA2B,GAA3B,UAEEhD,OAAkB,EAClBiD,YAAoB;IAEpB,IAAMC,WAAW,GAAG,IAAI,CAACC,qBAAqB,CAACnD,OAAO,EAAEiD,YAAY,CAAC;IACrE,IAAMG,OAAO,GAAG,IAAI,CAACC,yBAAyB,CAACH,WAAW,CAAC;IAC3D,OAAOE,OAAO;EAChB,CAAC;EAED9D,WAAA,CAAAF,SAAA,CAAAkE,iBAAiB,GAAjB,UAEE5C,eAA0B,EAC1B0C,OAAoB;IAEpB,IAAI,IAAI,CAACG,kCAAkC,CAAC7C,eAAe,EAAE0C,OAAO,CAAC,EAAE;MACrE,IAAMnD,WAAW,GAAG,IAAI,CAACF,gBAAgB,CAACW,eAAe,CAAC;MAC1D,OAAOT,WAAW;;IAGpB,IAAI,IAAI,CAACuD,iCAAiC,CAAC9C,eAAe,CAAC,EAAE;MAC3D,IAAM+C,OAAO,GAAG,IAAI,CAACnB,UAAU,EAAE;MACjC,IAAI,CAACoB,YAAY,EAAE;MACnB,OAAOD,OAAO;;IAGhB,MAAM,IAAIxE,uBAAuB,CAAC,eAAe,CAAC;EACpD,CAAC;EAEDK,WAAA,CAAAF,SAAA,CAAA2D,wBAAwB,GAAxB,UAEEY,aAAwB,EACxBP,OAAoB;IAEpB,OACE,IAAI,CAACG,kCAAkC,CAACI,aAAa,EAAEP,OAAO,CAAC,IAC/D,IAAI,CAACI,iCAAiC,CAACG,aAAa,CAAC;EAEzD,CAAC;EAEDrE,WAAA,CAAAF,SAAA,CAAAmE,kCAAkC,GAAlC,UAEE7C,eAA0B,EAC1B0C,OAAoB;IAHtB,IAAAzC,KAAA;IAKE,IAAI,CAAC,IAAI,CAACN,gCAAgC,CAACK,eAAe,CAAC,EAAE;MAC3D,OAAO,KAAK;;IAGd;IACA,IAAIhC,OAAA,CAAAkF,OAAO,CAACR,OAAO,CAAC,EAAE;MACpB,OAAO,KAAK;;IAGd,IAAMS,aAAa,GAAG,IAAI,CAAC1C,EAAE,CAAC,CAAC,CAAC;IAChC,IAAM2C,wBAAwB,GAC5BpF,OAAA,CAAAqF,IAAI,CAACX,OAAO,EAAE,UAACY,sBAAiC;MAC9C,OAAOrD,KAAI,CAACwB,YAAY,CAAC0B,aAAa,EAAEG,sBAAsB,CAAC;IACjE,CAAC,CAAC,KAAKnB,SAAS;IAElB,OAAOiB,wBAAwB;EACjC,CAAC;EAEDxE,WAAA,CAAAF,SAAA,CAAAoE,iCAAiC,GAAjC,UAEE9C,eAA0B;IAE1B,IAAMuD,yBAAyB,GAAG,IAAI,CAAC9B,YAAY,CACjD,IAAI,CAAChB,EAAE,CAAC,CAAC,CAAC,EACVT,eAAe,CAChB;IACD,OAAOuD,yBAAyB;EAClC,CAAC;EAED3E,WAAA,CAAAF,SAAA,CAAA8E,wBAAwB,GAAxB,UAEEC,YAAuB;IAEvB,IAAMC,SAAS,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzC,IAAMC,oBAAoB,GAAG,IAAI,CAACC,yBAAyB,CAACH,SAAS,CAAC;IACtE,OAAO1F,OAAA,CAAA8F,QAAQ,CAACF,oBAAoB,EAAEH,YAAY,CAAC;EACrD,CAAC;EAED7E,WAAA,CAAAF,SAAA,CAAAyB,mBAAmB,GAAnB;IACE,IAAM4D,yBAAyB,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzD;IACA,IAAIC,SAAS,GAAG,IAAI,CAACxD,EAAE,CAAC,CAAC,CAAC;IAC1B,IAAIyD,CAAC,GAAG,CAAC;IACT,OAAO,IAAI,EAAE;MACX,IAAMC,aAAa,GAAQF,SAAS,CAACG,SAAS;MAC9C,IAAIpG,OAAA,CAAA8F,QAAQ,CAACC,yBAAyB,EAAEI,aAAa,CAAC,EAAE;QACtD,OAAOA,aAAa;;MAEtBF,SAAS,GAAG,IAAI,CAACxD,EAAE,CAACyD,CAAC,CAAC;MACtBA,CAAC,EAAE;;EAEP,CAAC;EAEDtF,WAAA,CAAAF,SAAA,CAAAiF,gBAAgB,GAAhB;IACE;IACA,IAAI,IAAI,CAACU,UAAU,CAACC,MAAM,KAAK,CAAC,EAAE;MAChC,OAAOlG,OAAA,CAAAC,cAAc;;IAEvB,IAAMkG,iBAAiB,GAAG,IAAI,CAACC,4BAA4B,EAAE;IAC7D,IAAMC,WAAW,GAAG,IAAI,CAACC,kCAAkC,EAAE;IAC7D,IAAMC,iBAAiB,GAAG,IAAI,CAACC,gCAAgC,EAAE;IAEjE,OAAO;MACLzD,QAAQ,EAAE,IAAI,CAAC0D,uBAAuB,CAACN,iBAAiB,CAAC;MACzDO,gBAAgB,EAAEL,WAAW;MAC7BM,MAAM,EAAE,IAAI,CAACF,uBAAuB,CAACF,iBAAiB;KACvD;EACH,CAAC;EAED/F,WAAA,CAAAF,SAAA,CAAAsG,uBAAuB,GAAvB;IAAA,IAAA/E,KAAA;IACE,IAAMgF,iBAAiB,GAAG,IAAI,CAACZ,UAAU;IACzC,IAAMa,uBAAuB,GAAG,IAAI,CAACC,qBAAqB;IAE1D,OAAOnH,OAAA,CAAAoH,GAAG,CAACH,iBAAiB,EAAE,UAAC9D,QAAQ,EAAEkE,GAAG;MAC1C,IAAIA,GAAG,KAAK,CAAC,EAAE;QACb,OAAOjH,OAAA,CAAAC,cAAc;;MAEvB,OAAO;QACL8C,QAAQ,EAAElB,KAAI,CAAC4E,uBAAuB,CAAC1D,QAAQ,CAAC;QAChD2D,gBAAgB,EAAEI,uBAAuB,CAACG,GAAG,CAAC;QAC9CN,MAAM,EAAE9E,KAAI,CAAC4E,uBAAuB,CAACI,iBAAiB,CAACI,GAAG,GAAG,CAAC,CAAC;OAChE;IACH,CAAC,CAAC;EACJ,CAAC;EAEDzG,WAAA,CAAAF,SAAA,CAAAsF,gBAAgB,GAAhB;IAAA,IAAA/D,KAAA;IACE,IAAMqF,WAAW,GAAGtH,OAAA,CAAAoH,GAAG,CAAC,IAAI,CAACJ,uBAAuB,EAAE,EAAE,UAACO,OAAO;MAC9D,OAAOtF,KAAI,CAAC4D,yBAAyB,CAAC0B,OAAO,CAAC;IAChD,CAAC,CAAC;IACF,OAAYvH,OAAA,CAAAwH,OAAO,CAACF,WAAW,CAAC;EAClC,CAAC;EAED1G,WAAA,CAAAF,SAAA,CAAAmF,yBAAyB,GAAzB,UAEEH,SAAqB;IAErB,IAAIA,SAAS,KAAKtF,OAAA,CAAAC,cAAc,EAAE;MAChC,OAAO,CAACP,eAAA,CAAA2H,GAAG,CAAC;;IAGd,IAAMC,UAAU,GACdhC,SAAS,CAACvC,QAAQ,GAAGuC,SAAS,CAACoB,gBAAgB,GAAG5G,WAAA,CAAAyH,EAAE,GAAGjC,SAAS,CAACqB,MAAM;IAEzE,OAAO,IAAI,CAAC/F,aAAa,CAAC0G,UAAU,CAAC;EACvC,CAAC;EAED;EACA;EACA9G,WAAA,CAAAF,SAAA,CAAAmD,iBAAiB,GAAjB,UAEE+D,KAAa,EACbC,YAAsB;IAEtB,IAAI,CAAC,IAAI,CAACpE,YAAY,CAACmE,KAAK,EAAE9H,eAAA,CAAA2H,GAAG,CAAC,EAAE;MAClCI,YAAY,CAACC,IAAI,CAACF,KAAK,CAAC;;IAE1B,OAAOC,YAAY;EACrB,CAAC;EAEDjH,WAAA,CAAAF,SAAA,CAAAqH,QAAQ,GAAR,UAA8BzG,OAAkB;IAC9C,IAAMgB,cAAc,GAAG,EAAE;IACzB,IAAIyC,OAAO,GAAG,IAAI,CAACtC,EAAE,CAAC,CAAC,CAAC;IACxB,OAAO,IAAI,CAACgB,YAAY,CAACsB,OAAO,EAAEzD,OAAO,CAAC,KAAK,KAAK,EAAE;MACpDyD,OAAO,GAAG,IAAI,CAACnB,UAAU,EAAE;MAC3B,IAAI,CAACC,iBAAiB,CAACkB,OAAO,EAAEzC,cAAc,CAAC;;IAEjD;IACA,OAAOtC,OAAA,CAAAuD,SAAS,CAACjB,cAAc,CAAC;EAClC,CAAC;EAED1B,WAAA,CAAAF,SAAA,CAAAU,2BAA2B,GAA3B,UAEE4G,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChEnE,QAAkB;IAElB;IACA;EAAA,CACD;EAEDtD,WAAA,CAAAF,SAAA,CAAA+D,qBAAqB,GAArB,UAEEnD,OAAkB,EAClBiD,YAAoB;IAEpB,IAAM+D,aAAa,GAAa,IAAI,CAACC,yBAAyB,EAAE;IAChE,IAAMC,mBAAmB,GAAaxI,OAAA,CAAAyI,QAAQ,CAAC,IAAI,CAACtB,qBAAqB,CAAC;IAC1E,IAAM3C,WAAW,GAAQ;MACvBkE,SAAS,EAAEJ,aAAa;MACxBK,eAAe,EAAEH,mBAAmB;MACpCI,OAAO,EAAEtH,OAAO;MAChBuH,iBAAiB,EAAEtE;KACpB;IAED,OAAOC,WAAW;EACpB,CAAC;EACD5D,WAAA,CAAAF,SAAA,CAAA6H,yBAAyB,GAAzB;IAAA,IAAAtG,KAAA;IACE,OAAOjC,OAAA,CAAAoH,GAAG,CAAC,IAAI,CAACf,UAAU,EAAE,UAACyC,aAAa;MACxC,OAAA7G,KAAI,CAAC4E,uBAAuB,CAACiC,aAAa,CAAC;IAA3C,CAA2C,CAC5C;EACH,CAAC;EACH,OAAAlI,WAAC;AAAD,CAAC,CAnWD;AAAaR,OAAA,CAAAQ,WAAA,GAAAA,WAAA;AAqWb,SAAgBQ,2BAA2BA,CAEzC4G,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChEnE,QAAkB;EAElB,IAAM6E,GAAG,GAAG,IAAI,CAACC,2BAA2B,CAACb,YAAY,EAAEC,cAAc,CAAC;EAC1E,IAAIa,iBAAiB,GAAG,IAAI,CAAClI,gBAAgB,CAACgI,GAAG,CAAC;EAClD,IAAIE,iBAAiB,KAAK9E,SAAS,EAAE;IACnC,IAAM+E,YAAY,GAAG,IAAI,CAAC9F,mBAAmB,EAAE;IAC/C,IAAM+F,WAAW,GAAG,IAAI,CAACC,kBAAkB,EAAE,CAACF,YAAY,CAAC;IAC3D,IAAMG,MAAM,GAA8C,IAAIhB,cAAc,CAC1Ec,WAAW,EACXf,cAAc,CACf;IACDa,iBAAiB,GAAGI,MAAM,CAACC,YAAY,EAAE;IACzC,IAAI,CAACvI,gBAAgB,CAACgI,GAAG,CAAC,GAAGE,iBAAiB;;EAGhD,IAAIjF,uBAAuB,GAAGiF,iBAAiB,CAACrB,KAAK;EACrD,IAAI3D,UAAU,GAAGgF,iBAAiB,CAACM,UAAU;EAC7C,IAAMC,WAAW,GAAGP,iBAAiB,CAACO,WAAW;EAEjD;EACA;EACA,IACE,IAAI,CAACnD,UAAU,CAACC,MAAM,KAAK,CAAC,IAC5BkD,WAAW,IACXxF,uBAAuB,KAAKG,SAAS,EACrC;IACAH,uBAAuB,GAAGlE,eAAA,CAAA2H,GAAG;IAC7BxD,UAAU,GAAG,CAAC;;EAGhB,IACE,IAAI,CAACF,iCAAiC,CACpCC,uBAAuB,EACvBC,UAAU,EACVC,QAAQ,CACT,EACD;IACA;IACA;IACA;IACA,IAAI,CAACtC,uBAAuB,CAC1BoG,QAAQ,EACRC,IAAI,EACJC,aAAa,EACblE,uBAAuB,CACxB;;AAEL;AAvDA5D,OAAA,CAAAgB,2BAAA,GAAAA,2BAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}