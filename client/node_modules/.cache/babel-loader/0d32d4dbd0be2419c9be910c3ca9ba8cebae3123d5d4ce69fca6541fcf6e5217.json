{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar utils_1 = require(\"@chevrotain/utils\");\nvar reg_exp_1 = require(\"./reg_exp\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction disableSticky() {\n  exports.SUPPORT_STICKY = false;\n}\nexports.disableSticky = disableSticky;\nfunction enableSticky() {\n  exports.SUPPORT_STICKY = true;\n}\nexports.enableSticky = enableSticky;\nfunction analyzeTokenTypes(tokenTypes, options) {\n  options = utils_1.defaults(options, {\n    useSticky: exports.SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: function (msg, action) {\n      return action();\n    }\n  });\n  var tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n    initCharCodeToOptimizedIndexMap();\n  });\n  var onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", function () {\n    onlyRelevantTypes = utils_1.reject(tokenTypes, function (currType) {\n      return currType[PATTERN] === lexer_public_1.Lexer.NA;\n    });\n  });\n  var hasCustom = false;\n  var allTransformedPatterns;\n  tracer(\"Transform Patterns\", function () {\n    hasCustom = false;\n    allTransformedPatterns = utils_1.map(onlyRelevantTypes, function (currType) {\n      var currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n      if (utils_1.isRegExp(currPattern)) {\n        var regExpSource = currPattern.source;\n        if (regExpSource.length === 1 &&\n        // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" &&\n        // not a meta character\n        !utils_1.contains([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if (utils_1.isFunction(currPattern)) {\n        hasCustom = true;\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return {\n          exec: currPattern\n        };\n      } else if (utils_1.has(currPattern, \"exec\")) {\n        hasCustom = true;\n        // ICustomPattern\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          var wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  var patternIdxToType;\n  var patternIdxToGroup;\n  var patternIdxToLongerAltIdx;\n  var patternIdxToPushMode;\n  var patternIdxToPopMode;\n  tracer(\"misc mapping\", function () {\n    patternIdxToType = utils_1.map(onlyRelevantTypes, function (currType) {\n      return currType.tokenTypeIdx;\n    });\n    patternIdxToGroup = utils_1.map(onlyRelevantTypes, function (clazz) {\n      var groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === lexer_public_1.Lexer.SKIPPED) {\n        return undefined;\n      } else if (utils_1.isString(groupName)) {\n        return groupName;\n      } else if (utils_1.isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdx = utils_1.map(onlyRelevantTypes, function (clazz) {\n      var longerAltType = clazz.LONGER_ALT;\n      if (longerAltType) {\n        var longerAltIdx = utils_1.indexOf(onlyRelevantTypes, longerAltType);\n        return longerAltIdx;\n      }\n    });\n    patternIdxToPushMode = utils_1.map(onlyRelevantTypes, function (clazz) {\n      return clazz.PUSH_MODE;\n    });\n    patternIdxToPopMode = utils_1.map(onlyRelevantTypes, function (clazz) {\n      return utils_1.has(clazz, \"POP_MODE\");\n    });\n  });\n  var patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", function () {\n    var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) {\n      return false;\n    });\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) {\n        if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS;\n        } else {\n          if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n            return reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n          }\n        }\n      });\n    }\n  });\n  var patternIdxToIsCustom;\n  var patternIdxToShort;\n  var emptyGroups;\n  var patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", function () {\n    patternIdxToIsCustom = utils_1.map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = utils_1.map(allTransformedPatterns, isShortPattern);\n    emptyGroups = utils_1.reduce(onlyRelevantTypes, function (acc, clazz) {\n      var groupName = clazz.GROUP;\n      if (utils_1.isString(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n      return acc;\n    }, {});\n    patternIdxToConfig = utils_1.map(allTransformedPatterns, function (x, idx) {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdx[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  var canBeOptimized = true;\n  var charCodeToPatternIdxToConfig = [];\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", function () {\n      charCodeToPatternIdxToConfig = utils_1.reduce(onlyRelevantTypes, function (result, currTokType, idx) {\n        if (typeof currTokType.PATTERN === \"string\") {\n          var charCode = currTokType.PATTERN.charCodeAt(0);\n          var optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if (utils_1.isArray(currTokType.START_CHARS_HINT)) {\n          var lastOptimizedIdx_1;\n          utils_1.forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\n            var charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n            // Avoid adding the config multiple times\n            /* istanbul ignore else */\n            // - Difficult to check this scenario effects as it is only a performance\n            //   optimization that does not change correctness\n            if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n              lastOptimizedIdx_1 = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if (utils_1.isRegExp(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n            if (options.ensureOptimizations) {\n              utils_1.PRINT_ERROR(\"\" + reg_exp_1.failedOptimizationPrefixMsg + (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            var optimizedCodes = reg_exp_1.getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n            if (utils_1.isEmpty(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n            utils_1.forEach(optimizedCodes, function (code) {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            utils_1.PRINT_ERROR(\"\" + reg_exp_1.failedOptimizationPrefixMsg + (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n          canBeOptimized = false;\n        }\n        return result;\n      }, []);\n    });\n  }\n  tracer(\"ArrayPacking\", function () {\n    charCodeToPatternIdxToConfig = utils_1.packArray(charCodeToPatternIdxToConfig);\n  });\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\nexports.analyzeTokenTypes = analyzeTokenTypes;\nfunction validatePatterns(tokenTypes, validModesNames) {\n  var errors = [];\n  var missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  var invalidResult = findInvalidPatterns(missingResult.valid);\n  var validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenTypes) {\n  var errors = [];\n  var withRegExpPatterns = utils_1.filter(tokenTypes, function (currTokType) {\n    return utils_1.isRegExp(currTokType[PATTERN]);\n  });\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\nfunction findMissingPatterns(tokenTypes) {\n  var tokenTypesWithMissingPattern = utils_1.filter(tokenTypes, function (currType) {\n    return !utils_1.has(currType, PATTERN);\n  });\n  var errors = utils_1.map(tokenTypesWithMissingPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = utils_1.difference(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenTypes) {\n  var tokenTypesWithInvalidPattern = utils_1.filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return !utils_1.isRegExp(pattern) && !utils_1.isFunction(pattern) && !utils_1.has(pattern, \"exec\") && !utils_1.isString(pattern);\n  });\n  var errors = utils_1.map(tokenTypesWithInvalidPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = utils_1.difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][\\$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n  var EndAnchorFinder = /** @class */function (_super) {\n    __extends(EndAnchorFinder, _super);\n    function EndAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n      this.found = true;\n    };\n    return EndAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n  var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    try {\n      var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\n      var endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  var errors = utils_1.map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findEmptyMatchRegExps(tokenTypes) {\n  var matchesEmptyString = utils_1.filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern.test(\"\");\n  });\n  var errors = utils_1.map(matchesEmptyString, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n  var StartAnchorFinder = /** @class */function (_super) {\n    __extends(StartAnchorFinder, _super);\n    function StartAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n      this.found = true;\n    };\n    return StartAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n  var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    try {\n      var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\n      var startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  var errors = utils_1.map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\nfunction findUnsupportedFlags(tokenTypes) {\n  var invalidFlags = utils_1.filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  var errors = utils_1.map(invalidFlags, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenTypes) {\n  var found = [];\n  var identicalPatterns = utils_1.map(tokenTypes, function (outerType) {\n    return utils_1.reduce(tokenTypes, function (result, innerType) {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !utils_1.contains(found, innerType) && innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n      return result;\n    }, []);\n  });\n  identicalPatterns = utils_1.compact(identicalPatterns);\n  var duplicatePatterns = utils_1.filter(identicalPatterns, function (currIdenticalSet) {\n    return currIdenticalSet.length > 1;\n  });\n  var errors = utils_1.map(duplicatePatterns, function (setOfIdentical) {\n    var tokenTypeNames = utils_1.map(setOfIdentical, function (currType) {\n      return currType.name;\n    });\n    var dupPatternSrc = utils_1.first(setOfIdentical).PATTERN;\n    return {\n      message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" + (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n      type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenTypes) {\n  var invalidTypes = utils_1.filter(tokenTypes, function (clazz) {\n    if (!utils_1.has(clazz, \"GROUP\")) {\n      return false;\n    }\n    var group = clazz.GROUP;\n    return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !utils_1.isString(group);\n  });\n  var errors = utils_1.map(invalidTypes, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n  var invalidModes = utils_1.filter(tokenTypes, function (clazz) {\n    return clazz.PUSH_MODE !== undefined && !utils_1.contains(validModes, clazz.PUSH_MODE);\n  });\n  var errors = utils_1.map(invalidModes, function (tokType) {\n    var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" + \"which does not exist\";\n    return {\n      message: msg,\n      type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction findUnreachablePatterns(tokenTypes) {\n  var errors = [];\n  var canBeTested = utils_1.reduce(tokenTypes, function (result, tokType, idx) {\n    var pattern = tokType.PATTERN;\n    if (pattern === lexer_public_1.Lexer.NA) {\n      return result;\n    }\n    // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n    if (utils_1.isString(pattern)) {\n      result.push({\n        str: pattern,\n        idx: idx,\n        tokenType: tokType\n      });\n    } else if (utils_1.isRegExp(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx: idx,\n        tokenType: tokType\n      });\n    }\n    return result;\n  }, []);\n  utils_1.forEach(tokenTypes, function (tokType, testIdx) {\n    utils_1.forEach(canBeTested, function (_a) {\n      var str = _a.str,\n        idx = _a.idx,\n        tokenType = _a.tokenType;\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" + (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") + \"in the lexer's definition.\\n\" + \"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n        errors.push({\n          message: msg,\n          type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\nexports.findUnreachablePatterns = findUnreachablePatterns;\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if (utils_1.isRegExp(pattern)) {\n    var regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (utils_1.isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (utils_1.has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  var metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return utils_1.find(metaChars, function (char) {\n    return regExp.source.indexOf(char) !== -1;\n  }) === undefined;\n}\nfunction addStartOfInput(pattern) {\n  var flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction addStickyFlag(pattern) {\n  var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"\" + pattern.source, flags);\n}\nexports.addStickyFlag = addStickyFlag;\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var errors = [];\n  // some run time checks to help the end users.\n  if (!utils_1.has(lexerDefinition, exports.DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.DEFAULT_MODE + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n  if (!utils_1.has(lexerDefinition, exports.MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.MODES + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n  if (utils_1.has(lexerDefinition, exports.MODES) && utils_1.has(lexerDefinition, exports.DEFAULT_MODE) && !utils_1.has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized with a \" + exports.DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" + \"which does not exist\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n  if (utils_1.has(lexerDefinition, exports.MODES)) {\n    utils_1.forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n      utils_1.forEach(currModeValue, function (currTokType, currIdx) {\n        if (utils_1.isUndefined(currTokType)) {\n          errors.push({\n            message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" + (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        }\n      });\n    });\n  }\n  return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var warnings = [];\n  var hasAnyLineBreak = false;\n  var allTokenTypes = utils_1.compact(utils_1.flatten(utils_1.mapValues(lexerDefinition.modes, function (tokTypes) {\n    return tokTypes;\n  })));\n  var concreteTokenTypes = utils_1.reject(allTokenTypes, function (currType) {\n    return currType[PATTERN] === lexer_public_1.Lexer.NA;\n  });\n  var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    utils_1.forEach(concreteTokenTypes, function (tokType) {\n      var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        var message = buildLineBreakIssueMessage(tokType, currIssue);\n        var warningDescriptor = {\n          message: message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (reg_exp_1.canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n  return warnings;\n}\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\nfunction cloneEmptyGroups(emptyGroups) {\n  var clonedResult = {};\n  var groupKeys = utils_1.keys(emptyGroups);\n  utils_1.forEach(groupKeys, function (currKey) {\n    var currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n    if (utils_1.isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n// TODO: refactor to avoid duplication\nfunction isCustomPattern(tokenType) {\n  var pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (utils_1.isRegExp(pattern)) {\n    return false;\n  } else if (utils_1.isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (utils_1.has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (utils_1.isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexports.isCustomPattern = isCustomPattern;\nfunction isShortPattern(pattern) {\n  if (utils_1.isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexports.LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    var len = text.length;\n    for (var i = this.lastIndex; i < len; i++) {\n      var c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n  lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (utils_1.isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n      return false;\n    } else if (utils_1.isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\nfunction buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + (\"\\t Root cause: \" + details.errMsg + \".\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\nfunction getCharCodes(charsOrCodes) {\n  var charCodes = utils_1.map(charsOrCodes, function (numOrString) {\n    if (utils_1.isString(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\nexports.minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n  return charCode < exports.minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (utils_1.isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (var i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n      /* tslint:enable */\n    }\n  }\n}","map":{"version":3,"names":["regexp_to_ast_1","require","lexer_public_1","utils_1","reg_exp_1","reg_exp_parser_1","PATTERN","exports","DEFAULT_MODE","MODES","SUPPORT_STICKY","RegExp","sticky","disableSticky","enableSticky","analyzeTokenTypes","tokenTypes","options","defaults","useSticky","debug","safeMode","positionTracking","lineTerminatorCharacters","tracer","msg","action","initCharCodeToOptimizedIndexMap","onlyRelevantTypes","reject","currType","Lexer","NA","hasCustom","allTransformedPatterns","map","currPattern","isRegExp","regExpSource","source","length","ignoreCase","contains","addStickyFlag","addStartOfInput","isFunction","exec","has","escapedRegExpString","replace","wrappedRegExp","Error","patternIdxToType","patternIdxToGroup","patternIdxToLongerAltIdx","patternIdxToPushMode","patternIdxToPopMode","tokenTypeIdx","clazz","groupName","GROUP","SKIPPED","undefined","isString","isUndefined","longerAltType","LONGER_ALT","longerAltIdx","indexOf","PUSH_MODE","patternIdxToCanLineTerminator","lineTerminatorCharCodes","getCharCodes","tokType","LINE_BREAKS","checkLineBreaksIssues","canMatchCharCode","patternIdxToIsCustom","patternIdxToShort","emptyGroups","patternIdxToConfig","isCustomPattern","isShortPattern","reduce","acc","x","idx","pattern","longerAlt","canLineTerminator","isCustom","short","group","push","pop","tokenType","canBeOptimized","charCodeToPatternIdxToConfig","result","currTokType","charCode","charCodeAt","optimizedIdx","charCodeToOptimizedIndex","addToMapOfArrays","isArray","START_CHARS_HINT","lastOptimizedIdx_1","forEach","charOrInt","currOptimizedIdx","unicode","ensureOptimizations","PRINT_ERROR","failedOptimizationPrefixMsg","toString","optimizedCodes","getOptimizedStartCodesIndices","isEmpty","code","name","packArray","validatePatterns","validModesNames","errors","missingResult","findMissingPatterns","concat","invalidResult","findInvalidPatterns","valid","validTokenTypes","validateRegExpPattern","findInvalidGroupType","findModesThatDoNotExist","findUnreachablePatterns","withRegExpPatterns","filter","findEndOfInputAnchor","findStartOfInputAnchor","findUnsupportedFlags","findDuplicatePatterns","findEmptyMatchRegExps","tokenTypesWithMissingPattern","message","type","LexerDefinitionErrorType","MISSING_PATTERN","difference","tokenTypesWithInvalidPattern","INVALID_PATTERN","end_of_input","EndAnchorFinder","_super","__extends","_this","apply","arguments","found","prototype","visitEndAnchor","node","BaseRegExpVisitor","invalidRegex","regexpAst","getRegExpAst","endAnchorVisitor","visit","e","test","EOI_ANCHOR_FOUND","matchesEmptyString","EMPTY_MATCH_PATTERN","start_of_input","StartAnchorFinder","visitStartAnchor","startAnchorVisitor","SOI_ANCHOR_FOUND","invalidFlags","multiline","global","UNSUPPORTED_FLAGS_FOUND","identicalPatterns","outerType","innerType","compact","duplicatePatterns","currIdenticalSet","setOfIdentical","tokenTypeNames","dupPatternSrc","first","join","DUPLICATE_PATTERNS_FOUND","invalidTypes","INVALID_GROUP_TYPE_FOUND","validModes","invalidModes","PUSH_MODE_DOES_NOT_EXIST","canBeTested","str","noMetaChar","testIdx","_a","testTokenType","UNREACHABLE_PATTERN","regExpArray","index","regExp","metaChars","find","char","flags","performRuntimeChecks","lexerDefinition","trackLines","MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE","MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY","modes","defaultMode","MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST","currModeValue","currModeName","currIdx","LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED","performWarningRuntimeChecks","warnings","hasAnyLineBreak","allTokenTypes","flatten","mapValues","tokTypes","concreteTokenTypes","terminatorCharCodes","currIssue","buildLineBreakIssueMessage","warningDescriptor","issue","NO_LINE_BREAKS_FLAGS","cloneEmptyGroups","clonedResult","groupKeys","keys","currKey","currGroupValue","LineTerminatorOptimizedTester","text","len","i","lastIndex","c","IDENTIFY_TERMINATOR","errMsg","CUSTOM_LINE_BREAK","details","charsOrCodes","charCodes","numOrString","key","value","minOptimizationVal","charCodeToOptimizedIdxMap","Array"],"sources":["C:\\Users\\Work\\node_modules\\chevrotain\\src\\scan\\lexer.ts"],"sourcesContent":["import { BaseRegExpVisitor } from \"regexp-to-ast\"\nimport { IRegExpExec, Lexer, LexerDefinitionErrorType } from \"./lexer_public\"\nimport {\n  compact,\n  contains,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  mapValues,\n  packArray,\n  PRINT_ERROR,\n  reduce,\n  reject\n} from \"@chevrotain/utils\"\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices\n} from \"./reg_exp\"\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType\n} from \"@chevrotain/types\"\nimport { getRegExpAst } from \"./reg_exp_parser\"\n\nconst PATTERN = \"PATTERN\"\nexport const DEFAULT_MODE = \"defaultMode\"\nexport const MODES = \"modes\"\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec\n  longerAlt: number\n  canLineTerminator: boolean\n  isCustom: boolean\n  short: number | boolean\n  group: any\n  push: string\n  pop: boolean\n  tokenTypeIdx: number\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[]\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] }\n  emptyGroups: { [groupName: string]: IToken[] }\n  hasCustom: boolean\n  canBeOptimized: boolean\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\"\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\"\n    ensureOptimizations?: boolean\n    lineTerminatorCharacters?: (number | string)[]\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean\n    safeMode?: boolean\n    tracer?: (msg: string, action: Function) => void\n  }\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg, action) => action()\n  })\n\n  const tracer = options.tracer\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap()\n  })\n\n  let onlyRelevantTypes\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA\n    })\n  })\n\n  let hasCustom = false\n  let allTransformedPatterns\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false\n    allTransformedPatterns = map(onlyRelevantTypes, (currType) => {\n      const currPattern = currType[PATTERN]\n\n      /* istanbul ignore else */\n      if (isRegExp(currPattern)) {\n        const regExpSource = currPattern.source\n        if (\n          regExpSource.length === 1 &&\n          // only these regExp meta characters which can appear in a length one regExp\n          regExpSource !== \"^\" &&\n          regExpSource !== \"$\" &&\n          regExpSource !== \".\" &&\n          !currPattern.ignoreCase\n        ) {\n          return regExpSource\n        } else if (\n          regExpSource.length === 2 &&\n          regExpSource[0] === \"\\\\\" &&\n          // not a meta character\n          !contains(\n            [\n              \"d\",\n              \"D\",\n              \"s\",\n              \"S\",\n              \"t\",\n              \"r\",\n              \"n\",\n              \"t\",\n              \"0\",\n              \"c\",\n              \"b\",\n              \"B\",\n              \"f\",\n              \"v\",\n              \"w\",\n              \"W\"\n            ],\n            regExpSource[1]\n          )\n        ) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1]\n        } else {\n          return options.useSticky\n            ? addStickyFlag(currPattern)\n            : addStartOfInput(currPattern)\n        }\n      } else if (isFunction(currPattern)) {\n        hasCustom = true\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return { exec: currPattern }\n      } else if (has(currPattern, \"exec\")) {\n        hasCustom = true\n        // ICustomPattern\n        return currPattern\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern\n        } else {\n          const escapedRegExpString = currPattern.replace(\n            /[\\\\^$.*+?()[\\]{}|]/g,\n            \"\\\\$&\"\n          )\n          const wrappedRegExp = new RegExp(escapedRegExpString)\n          return options.useSticky\n            ? addStickyFlag(wrappedRegExp)\n            : addStartOfInput(wrappedRegExp)\n        }\n      } else {\n        throw Error(\"non exhaustive match\")\n      }\n    })\n  })\n\n  let patternIdxToType\n  let patternIdxToGroup\n  let patternIdxToLongerAltIdx\n  let patternIdxToPushMode\n  let patternIdxToPopMode\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx\n    )\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined\n      } else if (isString(groupName)) {\n        return groupName\n      } else if (isUndefined(groupName)) {\n        return false\n      } else {\n        throw Error(\"non exhaustive match\")\n      }\n    })\n\n    patternIdxToLongerAltIdx = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT\n\n      if (longerAltType) {\n        const longerAltIdx = indexOf(onlyRelevantTypes, longerAltType)\n        return longerAltIdx\n      }\n    })\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE\n    )\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\")\n    )\n  })\n\n  let patternIdxToCanLineTerminator\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters\n    )\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false)\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS\n        } else {\n          if (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false\n          ) {\n            return canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN)\n          }\n        }\n      })\n    }\n  })\n\n  let patternIdxToIsCustom\n  let patternIdxToShort\n  let emptyGroups\n  let patternIdxToConfig\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern)\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern)\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = []\n        }\n        return acc\n      },\n      {}\n    )\n\n    patternIdxToConfig = map(allTransformedPatterns, (x, idx) => {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdx[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      }\n    })\n  })\n\n  let canBeOptimized = true\n  let charCodeToPatternIdxToConfig = []\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0)\n            const optimizedIdx = charCodeToOptimizedIndex(charCode)\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx])\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode)\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx]\n                )\n              }\n            })\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\"\n                )\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations\n              )\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx])\n              })\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\"\n              )\n            }\n            canBeOptimized = false\n          }\n\n          return result\n        },\n        []\n      )\n    })\n  }\n  tracer(\"ArrayPacking\", () => {\n    charCodeToPatternIdxToConfig = packArray(charCodeToPatternIdxToConfig)\n  })\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  }\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[]\n): ILexerDefinitionError[] {\n  let errors = []\n\n  const missingResult = findMissingPatterns(tokenTypes)\n  errors = errors.concat(missingResult.errors)\n\n  const invalidResult = findInvalidPatterns(missingResult.valid)\n  const validTokenTypes = invalidResult.valid\n  errors = errors.concat(invalidResult.errors)\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes))\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes))\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames)\n  )\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes))\n\n  return errors\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  let errors = []\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN])\n  )\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns))\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns))\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns))\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns))\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns))\n\n  return errors\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[]\n  valid: TokenType[]\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[]\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN)\n  })\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern)\n  return { errors, valid }\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[]\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    )\n  })\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern)\n  return { errors, valid }\n}\n\nconst end_of_input = /[^\\\\][\\$]/\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false\n\n    visitEndAnchor(node) {\n      this.found = true\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n\n    try {\n      const regexpAst = getRegExpAst(pattern)\n      const endAnchorVisitor = new EndAnchorFinder()\n      endAnchorVisitor.visit(regexpAst)\n\n      return endAnchorVisitor.found\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source)\n    }\n  })\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return pattern.test(\"\")\n  })\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false\n\n    visitStartAnchor(node) {\n      this.found = true\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    try {\n      const regexpAst = getRegExpAst(pattern)\n      const startAnchorVisitor = new StartAnchorFinder()\n      startAnchorVisitor.visit(regexpAst)\n\n      return startAnchorVisitor.found\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source)\n    }\n  })\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN]\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global)\n  })\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const found = []\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType: any) => {\n        if (\n          outerType.PATTERN.source === innerType.PATTERN.source &&\n          !contains(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType)\n          result.push(innerType)\n          return result\n        }\n        return result\n      },\n      []\n    )\n  })\n\n  identicalPatterns = compact(identicalPatterns)\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1\n  })\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name\n    })\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \"\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    }\n  })\n\n  return errors\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false\n    }\n    const group = clazz.GROUP\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group)\n  })\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    }\n  })\n\n  return errors\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[]\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !contains(validModes, clazz.PUSH_MODE)\n    )\n  })\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    }\n  })\n\n  return errors\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[]\n): ILexerDefinitionError[] {\n  const errors = []\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN\n\n      if (pattern === Lexer.NA) {\n        return result\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType })\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType })\n      }\n      return result\n    },\n    []\n  )\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        })\n      }\n    })\n  })\n\n  return errors\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str)\n    return regExpArray !== null && regExpArray.index === 0\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {})\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {})\n  } else if (typeof pattern === \"string\") {\n    return pattern === str\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\"\n  ]\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  )\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\"\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags)\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\"\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags)\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[]\n): ILexerDefinitionError[] {\n  const errors = []\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    })\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    })\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type:\n        LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    })\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type:\n              LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          })\n        }\n      })\n    })\n  }\n\n  return errors\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[]\n): ILexerDefinitionError[] {\n  const warnings = []\n  let hasAnyLineBreak = false\n  const allTokenTypes = compact(\n    flatten(mapValues(lexerDefinition.modes, (tokTypes) => tokTypes))\n  )\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA\n  )\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters)\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes)\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue)\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType\n        }\n        warnings.push(warningDescriptor)\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true\n          }\n        } else {\n          if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true\n          }\n        }\n      }\n    })\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    })\n  }\n  return warnings\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {}\n  const groupKeys = keys(emptyGroups)\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey]\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = []\n    } else {\n      throw Error(\"non exhaustive match\")\n    }\n  })\n\n  return clonedResult\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: any): boolean {\n  const pattern = tokenType.PATTERN\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true\n  } else if (isString(pattern)) {\n    return false\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nexport function isShortPattern(pattern: any): number | boolean {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0)\n  } else {\n    return false\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i)\n      if (c === 10) {\n        this.lastIndex = i + 1\n        return true\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2\n        } else {\n          this.lastIndex = i + 1\n        }\n        return true\n      }\n    }\n    return false\n  },\n\n  lastIndex: 0\n}\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[]\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      errMsg?: string\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp)\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        }\n      }\n      return false\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK }\n    } else {\n      throw Error(\"non exhaustive match\")\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n    errMsg?: string\n  }\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    )\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    )\n  } else {\n    throw Error(\"non exhaustive match\")\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0)\n    } else {\n      return numOrString\n    }\n  })\n\n  return charCodes\n}\n\nfunction addToMapOfArrays(map, key, value): void {\n  if (map[key] === undefined) {\n    map[key] = [value]\n  } else {\n    map[key].push(value)\n  }\n}\n\nexport const minOptimizationVal = 256\n\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap = []\nexport function charCodeToOptimizedIndex(charCode) {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode]\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536)\n    for (let i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i\n      /* tslint:enable */\n    }\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAAA,eAAA,GAAAC,OAAA;AACA,IAAAC,cAAA,GAAAD,OAAA;AACA,IAAAE,OAAA,GAAAF,OAAA;AA0BA,IAAAG,SAAA,GAAAH,OAAA;AAYA,IAAAI,gBAAA,GAAAJ,OAAA;AAEA,IAAMK,OAAO,GAAG,SAAS;AACZC,OAAA,CAAAC,YAAY,GAAG,aAAa;AAC5BD,OAAA,CAAAE,KAAK,GAAG,OAAO;AAsBjBF,OAAA,CAAAG,cAAc,GACvB,OAAa,IAAIC,MAAM,CAAC,MAAM,CAAE,CAACC,MAAM,KAAK,SAAS;AAEvD,SAAgBC,aAAaA,CAAA;EAC3BN,OAAA,CAAAG,cAAc,GAAG,KAAK;AACxB;AAFAH,OAAA,CAAAM,aAAA,GAAAA,aAAA;AAIA,SAAgBC,YAAYA,CAAA;EAC1BP,OAAA,CAAAG,cAAc,GAAG,IAAI;AACvB;AAFAH,OAAA,CAAAO,YAAA,GAAAA,YAAA;AAIA,SAAgBC,iBAAiBA,CAC/BC,UAAuB,EACvBC,OAQC;EAEDA,OAAO,GAAGd,OAAA,CAAAe,QAAQ,CAACD,OAAO,EAAE;IAC1BE,SAAS,EAAEZ,OAAA,CAAAG,cAAc;IACzBU,KAAK,EAAE,KAAK;IACZC,QAAQ,EAAE,KAAK;IACfC,gBAAgB,EAAE,MAAM;IACxBC,wBAAwB,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC;IACtCC,MAAM,EAAE,SAAAA,CAACC,GAAG,EAAEC,MAAM;MAAK,OAAAA,MAAM,EAAE;IAAR;GAC1B,CAAC;EAEF,IAAMF,MAAM,GAAGP,OAAO,CAACO,MAAM;EAE7BA,MAAM,CAAC,iCAAiC,EAAE;IACxCG,+BAA+B,EAAE;EACnC,CAAC,CAAC;EAEF,IAAIC,iBAAiB;EACrBJ,MAAM,CAAC,iBAAiB,EAAE;IACxBI,iBAAiB,GAAGzB,OAAA,CAAA0B,MAAM,CAACb,UAAU,EAAE,UAACc,QAAQ;MAC9C,OAAOA,QAAQ,CAACxB,OAAO,CAAC,KAAKJ,cAAA,CAAA6B,KAAK,CAACC,EAAE;IACvC,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,IAAIC,SAAS,GAAG,KAAK;EACrB,IAAIC,sBAAsB;EAC1BV,MAAM,CAAC,oBAAoB,EAAE;IAC3BS,SAAS,GAAG,KAAK;IACjBC,sBAAsB,GAAG/B,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAACE,QAAQ;MACvD,IAAMM,WAAW,GAAGN,QAAQ,CAACxB,OAAO,CAAC;MAErC;MACA,IAAIH,OAAA,CAAAkC,QAAQ,CAACD,WAAW,CAAC,EAAE;QACzB,IAAME,YAAY,GAAGF,WAAW,CAACG,MAAM;QACvC,IACED,YAAY,CAACE,MAAM,KAAK,CAAC;QACzB;QACAF,YAAY,KAAK,GAAG,IACpBA,YAAY,KAAK,GAAG,IACpBA,YAAY,KAAK,GAAG,IACpB,CAACF,WAAW,CAACK,UAAU,EACvB;UACA,OAAOH,YAAY;SACpB,MAAM,IACLA,YAAY,CAACE,MAAM,KAAK,CAAC,IACzBF,YAAY,CAAC,CAAC,CAAC,KAAK,IAAI;QACxB;QACA,CAACnC,OAAA,CAAAuC,QAAQ,CACP,CACE,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,CACJ,EACDJ,YAAY,CAAC,CAAC,CAAC,CAChB,EACD;UACA;UACA;UACA;UACA,OAAOA,YAAY,CAAC,CAAC,CAAC;SACvB,MAAM;UACL,OAAOrB,OAAO,CAACE,SAAS,GACpBwB,aAAa,CAACP,WAAW,CAAC,GAC1BQ,eAAe,CAACR,WAAW,CAAC;;OAEnC,MAAM,IAAIjC,OAAA,CAAA0C,UAAU,CAACT,WAAW,CAAC,EAAE;QAClCH,SAAS,GAAG,IAAI;QAChB;QACA,OAAO;UAAEa,IAAI,EAAEV;QAAW,CAAE;OAC7B,MAAM,IAAIjC,OAAA,CAAA4C,GAAG,CAACX,WAAW,EAAE,MAAM,CAAC,EAAE;QACnCH,SAAS,GAAG,IAAI;QAChB;QACA,OAAOG,WAAW;OACnB,MAAM,IAAI,OAAOA,WAAW,KAAK,QAAQ,EAAE;QAC1C,IAAIA,WAAW,CAACI,MAAM,KAAK,CAAC,EAAE;UAC5B,OAAOJ,WAAW;SACnB,MAAM;UACL,IAAMY,mBAAmB,GAAGZ,WAAW,CAACa,OAAO,CAC7C,qBAAqB,EACrB,MAAM,CACP;UACD,IAAMC,aAAa,GAAG,IAAIvC,MAAM,CAACqC,mBAAmB,CAAC;UACrD,OAAO/B,OAAO,CAACE,SAAS,GACpBwB,aAAa,CAACO,aAAa,CAAC,GAC5BN,eAAe,CAACM,aAAa,CAAC;;OAErC,MAAM;QACL,MAAMC,KAAK,CAAC,sBAAsB,CAAC;;IAEvC,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,IAAIC,gBAAgB;EACpB,IAAIC,iBAAiB;EACrB,IAAIC,wBAAwB;EAC5B,IAAIC,oBAAoB;EACxB,IAAIC,mBAAmB;EACvBhC,MAAM,CAAC,cAAc,EAAE;IACrB4B,gBAAgB,GAAGjD,OAAA,CAAAgC,GAAG,CACpBP,iBAAiB,EACjB,UAACE,QAAQ;MAAK,OAAAA,QAAQ,CAAC2B,YAAY;IAArB,CAAqB,CACpC;IAEDJ,iBAAiB,GAAGlD,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAAC8B,KAAU;MACpD,IAAMC,SAAS,GAAGD,KAAK,CAACE,KAAK;MAC7B;MACA,IAAID,SAAS,KAAKzD,cAAA,CAAA6B,KAAK,CAAC8B,OAAO,EAAE;QAC/B,OAAOC,SAAS;OACjB,MAAM,IAAI3D,OAAA,CAAA4D,QAAQ,CAACJ,SAAS,CAAC,EAAE;QAC9B,OAAOA,SAAS;OACjB,MAAM,IAAIxD,OAAA,CAAA6D,WAAW,CAACL,SAAS,CAAC,EAAE;QACjC,OAAO,KAAK;OACb,MAAM;QACL,MAAMR,KAAK,CAAC,sBAAsB,CAAC;;IAEvC,CAAC,CAAC;IAEFG,wBAAwB,GAAGnD,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAAC8B,KAAU;MAC3D,IAAMO,aAAa,GAAGP,KAAK,CAACQ,UAAU;MAEtC,IAAID,aAAa,EAAE;QACjB,IAAME,YAAY,GAAGhE,OAAA,CAAAiE,OAAO,CAACxC,iBAAiB,EAAEqC,aAAa,CAAC;QAC9D,OAAOE,YAAY;;IAEvB,CAAC,CAAC;IAEFZ,oBAAoB,GAAGpD,OAAA,CAAAgC,GAAG,CACxBP,iBAAiB,EACjB,UAAC8B,KAAU;MAAK,OAAAA,KAAK,CAACW,SAAS;IAAf,CAAe,CAChC;IAEDb,mBAAmB,GAAGrD,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAAC8B,KAAU;MACtD,OAAAvD,OAAA,CAAA4C,GAAG,CAACW,KAAK,EAAE,UAAU,CAAC;IAAtB,CAAsB,CACvB;EACH,CAAC,CAAC;EAEF,IAAIY,6BAA6B;EACjC9C,MAAM,CAAC,0BAA0B,EAAE;IACjC,IAAM+C,uBAAuB,GAAGC,YAAY,CAC1CvD,OAAO,CAACM,wBAAwB,CACjC;IACD+C,6BAA6B,GAAGnE,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAAC6C,OAAO;MAAK,YAAK;IAAL,CAAK,CAAC;IAC1E,IAAIxD,OAAO,CAACK,gBAAgB,KAAK,YAAY,EAAE;MAC7CgD,6BAA6B,GAAGnE,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAE,UAAC6C,OAAO;QAC7D,IAAItE,OAAA,CAAA4C,GAAG,CAAC0B,OAAO,EAAE,aAAa,CAAC,EAAE;UAC/B,OAAOA,OAAO,CAACC,WAAW;SAC3B,MAAM;UACL,IACEC,qBAAqB,CAACF,OAAO,EAAEF,uBAAuB,CAAC,KAAK,KAAK,EACjE;YACA,OAAOnE,SAAA,CAAAwE,gBAAgB,CAACL,uBAAuB,EAAEE,OAAO,CAACnE,OAAO,CAAC;;;MAGvE,CAAC,CAAC;;EAEN,CAAC,CAAC;EAEF,IAAIuE,oBAAoB;EACxB,IAAIC,iBAAiB;EACrB,IAAIC,WAAW;EACf,IAAIC,kBAAkB;EACtBxD,MAAM,CAAC,iBAAiB,EAAE;IACxBqD,oBAAoB,GAAG1E,OAAA,CAAAgC,GAAG,CAACP,iBAAiB,EAAEqD,eAAe,CAAC;IAC9DH,iBAAiB,GAAG3E,OAAA,CAAAgC,GAAG,CAACD,sBAAsB,EAAEgD,cAAc,CAAC;IAE/DH,WAAW,GAAG5E,OAAA,CAAAgF,MAAM,CAClBvD,iBAAiB,EACjB,UAACwD,GAAG,EAAE1B,KAAU;MACd,IAAMC,SAAS,GAAGD,KAAK,CAACE,KAAK;MAC7B,IAAIzD,OAAA,CAAA4D,QAAQ,CAACJ,SAAS,CAAC,IAAI,EAAEA,SAAS,KAAKzD,cAAA,CAAA6B,KAAK,CAAC8B,OAAO,CAAC,EAAE;QACzDuB,GAAG,CAACzB,SAAS,CAAC,GAAG,EAAE;;MAErB,OAAOyB,GAAG;IACZ,CAAC,EACD,EAAE,CACH;IAEDJ,kBAAkB,GAAG7E,OAAA,CAAAgC,GAAG,CAACD,sBAAsB,EAAE,UAACmD,CAAC,EAAEC,GAAG;MACtD,OAAO;QACLC,OAAO,EAAErD,sBAAsB,CAACoD,GAAG,CAAC;QACpCE,SAAS,EAAElC,wBAAwB,CAACgC,GAAG,CAAC;QACxCG,iBAAiB,EAAEnB,6BAA6B,CAACgB,GAAG,CAAC;QACrDI,QAAQ,EAAEb,oBAAoB,CAACS,GAAG,CAAC;QACnCK,KAAK,EAAEb,iBAAiB,CAACQ,GAAG,CAAC;QAC7BM,KAAK,EAAEvC,iBAAiB,CAACiC,GAAG,CAAC;QAC7BO,IAAI,EAAEtC,oBAAoB,CAAC+B,GAAG,CAAC;QAC/BQ,GAAG,EAAEtC,mBAAmB,CAAC8B,GAAG,CAAC;QAC7B7B,YAAY,EAAEL,gBAAgB,CAACkC,GAAG,CAAC;QACnCS,SAAS,EAAEnE,iBAAiB,CAAC0D,GAAG;OACjC;IACH,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,IAAIU,cAAc,GAAG,IAAI;EACzB,IAAIC,4BAA4B,GAAG,EAAE;EAErC,IAAI,CAAChF,OAAO,CAACI,QAAQ,EAAE;IACrBG,MAAM,CAAC,yBAAyB,EAAE;MAChCyE,4BAA4B,GAAG9F,OAAA,CAAAgF,MAAM,CACnCvD,iBAAiB,EACjB,UAACsE,MAAM,EAAEC,WAAW,EAAEb,GAAG;QACvB,IAAI,OAAOa,WAAW,CAAC7F,OAAO,KAAK,QAAQ,EAAE;UAC3C,IAAM8F,QAAQ,GAAGD,WAAW,CAAC7F,OAAO,CAAC+F,UAAU,CAAC,CAAC,CAAC;UAClD,IAAMC,YAAY,GAAGC,wBAAwB,CAACH,QAAQ,CAAC;UACvDI,gBAAgB,CAACN,MAAM,EAAEI,YAAY,EAAEtB,kBAAkB,CAACM,GAAG,CAAC,CAAC;SAChE,MAAM,IAAInF,OAAA,CAAAsG,OAAO,CAACN,WAAW,CAACO,gBAAgB,CAAC,EAAE;UAChD,IAAIC,kBAAgB;UACpBxG,OAAA,CAAAyG,OAAO,CAACT,WAAW,CAACO,gBAAgB,EAAE,UAACG,SAAS;YAC9C,IAAMT,QAAQ,GACZ,OAAOS,SAAS,KAAK,QAAQ,GACzBA,SAAS,CAACR,UAAU,CAAC,CAAC,CAAC,GACvBQ,SAAS;YACf,IAAMC,gBAAgB,GAAGP,wBAAwB,CAACH,QAAQ,CAAC;YAC3D;YACA;YACA;YACA;YACA,IAAIO,kBAAgB,KAAKG,gBAAgB,EAAE;cACzCH,kBAAgB,GAAGG,gBAAgB;cACnCN,gBAAgB,CACdN,MAAM,EACNY,gBAAgB,EAChB9B,kBAAkB,CAACM,GAAG,CAAC,CACxB;;UAEL,CAAC,CAAC;SACH,MAAM,IAAInF,OAAA,CAAAkC,QAAQ,CAAC8D,WAAW,CAAC7F,OAAO,CAAC,EAAE;UACxC,IAAI6F,WAAW,CAAC7F,OAAO,CAACyG,OAAO,EAAE;YAC/Bf,cAAc,GAAG,KAAK;YACtB,IAAI/E,OAAO,CAAC+F,mBAAmB,EAAE;cAC/B7G,OAAA,CAAA8G,WAAW,CACT,KAAG7G,SAAA,CAAA8G,2BAA6B,IAC9B,2BAAyBf,WAAW,CAAC7F,OAAO,CAAC6G,QAAQ,EAAE,kBAAe,IACtE,sFAAsF,GACtF,6DAA6D,GAC7D,kGAAkG,CACrG;;WAEJ,MAAM;YACL,IAAMC,cAAc,GAAGhH,SAAA,CAAAiH,6BAA6B,CAClDlB,WAAW,CAAC7F,OAAO,EACnBW,OAAO,CAAC+F,mBAAmB,CAC5B;YACD;YACA;YACA;YACA,IAAI7G,OAAA,CAAAmH,OAAO,CAACF,cAAc,CAAC,EAAE;cAC3B;cACA;cACA;cACApB,cAAc,GAAG,KAAK;;YAExB7F,OAAA,CAAAyG,OAAO,CAACQ,cAAc,EAAE,UAACG,IAAI;cAC3Bf,gBAAgB,CAACN,MAAM,EAAEqB,IAAI,EAAEvC,kBAAkB,CAACM,GAAG,CAAC,CAAC;YACzD,CAAC,CAAC;;SAEL,MAAM;UACL,IAAIrE,OAAO,CAAC+F,mBAAmB,EAAE;YAC/B7G,OAAA,CAAA8G,WAAW,CACT,KAAG7G,SAAA,CAAA8G,2BAA6B,IAC9B,mBAAiBf,WAAW,CAACqB,IAAI,wFAAqF,IACtH,6DAA6D,GAC7D,iGAAiG,CACpG;;UAEHxB,cAAc,GAAG,KAAK;;QAGxB,OAAOE,MAAM;MACf,CAAC,EACD,EAAE,CACH;IACH,CAAC,CAAC;;EAEJ1E,MAAM,CAAC,cAAc,EAAE;IACrByE,4BAA4B,GAAG9F,OAAA,CAAAsH,SAAS,CAACxB,4BAA4B,CAAC;EACxE,CAAC,CAAC;EAEF,OAAO;IACLlB,WAAW,EAAEA,WAAW;IACxBC,kBAAkB,EAAEA,kBAAkB;IACtCiB,4BAA4B,EAAEA,4BAA4B;IAC1DhE,SAAS,EAAEA,SAAS;IACpB+D,cAAc,EAAEA;GACjB;AACH;AApTAzF,OAAA,CAAAQ,iBAAA,GAAAA,iBAAA;AAsTA,SAAgB2G,gBAAgBA,CAC9B1G,UAAuB,EACvB2G,eAAyB;EAEzB,IAAIC,MAAM,GAAG,EAAE;EAEf,IAAMC,aAAa,GAAGC,mBAAmB,CAAC9G,UAAU,CAAC;EACrD4G,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACF,aAAa,CAACD,MAAM,CAAC;EAE5C,IAAMI,aAAa,GAAGC,mBAAmB,CAACJ,aAAa,CAACK,KAAK,CAAC;EAC9D,IAAMC,eAAe,GAAGH,aAAa,CAACE,KAAK;EAC3CN,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACC,aAAa,CAACJ,MAAM,CAAC;EAE5CA,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACK,qBAAqB,CAACD,eAAe,CAAC,CAAC;EAE9DP,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACM,oBAAoB,CAACF,eAAe,CAAC,CAAC;EAE7DP,MAAM,GAAGA,MAAM,CAACG,MAAM,CACpBO,uBAAuB,CAACH,eAAe,EAAER,eAAe,CAAC,CAC1D;EAEDC,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACQ,uBAAuB,CAACJ,eAAe,CAAC,CAAC;EAEhE,OAAOP,MAAM;AACf;AAxBArH,OAAA,CAAAmH,gBAAA,GAAAA,gBAAA;AA0BA,SAASU,qBAAqBA,CAC5BpH,UAAuB;EAEvB,IAAI4G,MAAM,GAAG,EAAE;EACf,IAAMY,kBAAkB,GAAGrI,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACmF,WAAW;IACxD,OAAAhG,OAAA,CAAAkC,QAAQ,CAAC8D,WAAW,CAAC7F,OAAO,CAAC,CAAC;EAA9B,CAA8B,CAC/B;EAEDsH,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACW,oBAAoB,CAACF,kBAAkB,CAAC,CAAC;EAEhEZ,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACY,sBAAsB,CAACH,kBAAkB,CAAC,CAAC;EAElEZ,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACa,oBAAoB,CAACJ,kBAAkB,CAAC,CAAC;EAEhEZ,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACc,qBAAqB,CAACL,kBAAkB,CAAC,CAAC;EAEjEZ,MAAM,GAAGA,MAAM,CAACG,MAAM,CAACe,qBAAqB,CAACN,kBAAkB,CAAC,CAAC;EAEjE,OAAOZ,MAAM;AACf;AAOA,SAAgBE,mBAAmBA,CACjC9G,UAAuB;EAEvB,IAAM+H,4BAA4B,GAAG5I,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IAC/D,OAAO,CAAC3B,OAAA,CAAA4C,GAAG,CAACjB,QAAQ,EAAExB,OAAO,CAAC;EAChC,CAAC,CAAC;EAEF,IAAMsH,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAAC4G,4BAA4B,EAAE,UAACjH,QAAQ;IACxD,OAAO;MACLkH,OAAO,EACL,gBAAgB,GAChBlH,QAAQ,CAAC0F,IAAI,GACb,sCAAsC;MACxCyB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACC,eAAe;MAC9CnI,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,IAAMoG,KAAK,GAAG/H,OAAA,CAAAiJ,UAAU,CAACpI,UAAU,EAAE+H,4BAA4B,CAAC;EAClE,OAAO;IAAEnB,MAAM,EAAAA,MAAA;IAAEM,KAAK,EAAAA;EAAA,CAAE;AAC1B;AApBA3H,OAAA,CAAAuH,mBAAA,GAAAA,mBAAA;AAsBA,SAAgBG,mBAAmBA,CACjCjH,UAAuB;EAEvB,IAAMqI,4BAA4B,GAAGlJ,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IAC/D,IAAMyD,OAAO,GAAGzD,QAAQ,CAACxB,OAAO,CAAC;IACjC,OACE,CAACH,OAAA,CAAAkC,QAAQ,CAACkD,OAAO,CAAC,IAClB,CAACpF,OAAA,CAAA0C,UAAU,CAAC0C,OAAO,CAAC,IACpB,CAACpF,OAAA,CAAA4C,GAAG,CAACwC,OAAO,EAAE,MAAM,CAAC,IACrB,CAACpF,OAAA,CAAA4D,QAAQ,CAACwB,OAAO,CAAC;EAEtB,CAAC,CAAC;EAEF,IAAMqC,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACkH,4BAA4B,EAAE,UAACvH,QAAQ;IACxD,OAAO;MACLkH,OAAO,EACL,gBAAgB,GAChBlH,QAAQ,CAAC0F,IAAI,GACb,6CAA6C,GAC7C,8GAA8G;MAChHyB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACI,eAAe;MAC9CtI,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,IAAMoG,KAAK,GAAG/H,OAAA,CAAAiJ,UAAU,CAACpI,UAAU,EAAEqI,4BAA4B,CAAC;EAClE,OAAO;IAAEzB,MAAM,EAAAA,MAAA;IAAEM,KAAK,EAAAA;EAAA,CAAE;AAC1B;AA3BA3H,OAAA,CAAA0H,mBAAA,GAAAA,mBAAA;AA6BA,IAAMsB,YAAY,GAAG,WAAW;AAEhC,SAAgBb,oBAAoBA,CAClC1H,UAAuB;EAEvB,IAAAwI,eAAA,0BAAAC,MAAA;IAA8BC,SAAA,CAAAF,eAAA,EAAAC,MAAA;IAA9B,SAAAD,gBAAA;MAAA,IAAAG,KAAA,GAAAF,MAAA,aAAAA,MAAA,CAAAG,KAAA,OAAAC,SAAA;MACEF,KAAA,CAAAG,KAAK,GAAG,KAAK;;IAKf;IAHEN,eAAA,CAAAO,SAAA,CAAAC,cAAc,GAAd,UAAeC,IAAI;MACjB,IAAI,CAACH,KAAK,GAAG,IAAI;IACnB,CAAC;IACH,OAAAN,eAAC;EAAD,CAAC,CAN6BxJ,eAAA,CAAAkK,iBAAiB;EAQ/C,IAAMC,YAAY,GAAGhK,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IAC/C,IAAMyD,OAAO,GAAGzD,QAAQ,CAACxB,OAAO,CAAC;IAEjC,IAAI;MACF,IAAM8J,SAAS,GAAG/J,gBAAA,CAAAgK,YAAY,CAAC9E,OAAO,CAAC;MACvC,IAAM+E,gBAAgB,GAAG,IAAId,eAAe,EAAE;MAC9Cc,gBAAgB,CAACC,KAAK,CAACH,SAAS,CAAC;MAEjC,OAAOE,gBAAgB,CAACR,KAAK;KAC9B,CAAC,OAAOU,CAAC,EAAE;MACV;MACA;MACA,OAAOjB,YAAY,CAACkB,IAAI,CAAClF,OAAO,CAAChD,MAAM,CAAC;;EAE5C,CAAC,CAAC;EAEF,IAAMqF,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACgI,YAAY,EAAE,UAACrI,QAAQ;IACxC,OAAO;MACLkH,OAAO,EACL,mCAAmC,GACnC,kBAAkB,GAClBlH,QAAQ,CAAC0F,IAAI,GACb,8DAA8D,GAC9D,oEAAoE,GACpE,gBAAgB;MAClByB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACwB,gBAAgB;MAC/C1J,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO8F,MAAM;AACf;AA1CArH,OAAA,CAAAmI,oBAAA,GAAAA,oBAAA;AA4CA,SAAgBI,qBAAqBA,CACnC9H,UAAuB;EAEvB,IAAM2J,kBAAkB,GAAGxK,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IACrD,IAAMyD,OAAO,GAAGzD,QAAQ,CAACxB,OAAO,CAAC;IACjC,OAAOiF,OAAO,CAACkF,IAAI,CAAC,EAAE,CAAC;EACzB,CAAC,CAAC;EAEF,IAAM7C,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACwI,kBAAkB,EAAE,UAAC7I,QAAQ;IAC9C,OAAO;MACLkH,OAAO,EACL,gBAAgB,GAChBlH,QAAQ,CAAC0F,IAAI,GACb,oDAAoD;MACtDyB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAAC0B,mBAAmB;MAClD5J,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO8F,MAAM;AACf;AApBArH,OAAA,CAAAuI,qBAAA,GAAAA,qBAAA;AAsBA,IAAM+B,cAAc,GAAG,gBAAgB;AAEvC,SAAgBlC,sBAAsBA,CACpC3H,UAAuB;EAEvB,IAAA8J,iBAAA,0BAAArB,MAAA;IAAgCC,SAAA,CAAAoB,iBAAA,EAAArB,MAAA;IAAhC,SAAAqB,kBAAA;MAAA,IAAAnB,KAAA,GAAAF,MAAA,aAAAA,MAAA,CAAAG,KAAA,OAAAC,SAAA;MACEF,KAAA,CAAAG,KAAK,GAAG,KAAK;;IAKf;IAHEgB,iBAAA,CAAAf,SAAA,CAAAgB,gBAAgB,GAAhB,UAAiBd,IAAI;MACnB,IAAI,CAACH,KAAK,GAAG,IAAI;IACnB,CAAC;IACH,OAAAgB,iBAAC;EAAD,CAAC,CAN+B9K,eAAA,CAAAkK,iBAAiB;EAQjD,IAAMC,YAAY,GAAGhK,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IAC/C,IAAMyD,OAAO,GAAGzD,QAAQ,CAACxB,OAAO,CAAC;IACjC,IAAI;MACF,IAAM8J,SAAS,GAAG/J,gBAAA,CAAAgK,YAAY,CAAC9E,OAAO,CAAC;MACvC,IAAMyF,kBAAkB,GAAG,IAAIF,iBAAiB,EAAE;MAClDE,kBAAkB,CAACT,KAAK,CAACH,SAAS,CAAC;MAEnC,OAAOY,kBAAkB,CAAClB,KAAK;KAChC,CAAC,OAAOU,CAAC,EAAE;MACV;MACA;MACA,OAAOK,cAAc,CAACJ,IAAI,CAAClF,OAAO,CAAChD,MAAM,CAAC;;EAE9C,CAAC,CAAC;EAEF,IAAMqF,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACgI,YAAY,EAAE,UAACrI,QAAQ;IACxC,OAAO;MACLkH,OAAO,EACL,mCAAmC,GACnC,kBAAkB,GAClBlH,QAAQ,CAAC0F,IAAI,GACb,gEAAgE,GAChE,4EAA4E,GAC5E,gBAAgB;MAClByB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAAC+B,gBAAgB;MAC/CjK,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO8F,MAAM;AACf;AAzCArH,OAAA,CAAAoI,sBAAA,GAAAA,sBAAA;AA2CA,SAAgBC,oBAAoBA,CAClC5H,UAAuB;EAEvB,IAAMkK,YAAY,GAAG/K,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAACc,QAAQ;IAC/C,IAAMyD,OAAO,GAAGzD,QAAQ,CAACxB,OAAO,CAAC;IACjC,OAAOiF,OAAO,YAAY5E,MAAM,KAAK4E,OAAO,CAAC4F,SAAS,IAAI5F,OAAO,CAAC6F,MAAM,CAAC;EAC3E,CAAC,CAAC;EAEF,IAAMxD,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAAC+I,YAAY,EAAE,UAACpJ,QAAQ;IACxC,OAAO;MACLkH,OAAO,EACL,gBAAgB,GAChBlH,QAAQ,CAAC0F,IAAI,GACb,mEAAmE;MACrEyB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACmC,uBAAuB;MACtDrK,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO8F,MAAM;AACf;AApBArH,OAAA,CAAAqI,oBAAA,GAAAA,oBAAA;AAsBA;AACA,SAAgBC,qBAAqBA,CACnC7H,UAAuB;EAEvB,IAAM8I,KAAK,GAAG,EAAE;EAChB,IAAIwB,iBAAiB,GAAGnL,OAAA,CAAAgC,GAAG,CAACnB,UAAU,EAAE,UAACuK,SAAc;IACrD,OAAOpL,OAAA,CAAAgF,MAAM,CACXnE,UAAU,EACV,UAACkF,MAAM,EAAEsF,SAAc;MACrB,IACED,SAAS,CAACjL,OAAO,CAACiC,MAAM,KAAKiJ,SAAS,CAAClL,OAAO,CAACiC,MAAM,IACrD,CAACpC,OAAA,CAAAuC,QAAQ,CAACoH,KAAK,EAAE0B,SAAS,CAAC,IAC3BA,SAAS,CAAClL,OAAO,KAAKJ,cAAA,CAAA6B,KAAK,CAACC,EAAE,EAC9B;QACA;QACA;QACA8H,KAAK,CAACjE,IAAI,CAAC2F,SAAS,CAAC;QACrBtF,MAAM,CAACL,IAAI,CAAC2F,SAAS,CAAC;QACtB,OAAOtF,MAAM;;MAEf,OAAOA,MAAM;IACf,CAAC,EACD,EAAE,CACH;EACH,CAAC,CAAC;EAEFoF,iBAAiB,GAAGnL,OAAA,CAAAsL,OAAO,CAACH,iBAAiB,CAAC;EAE9C,IAAMI,iBAAiB,GAAGvL,OAAA,CAAAsI,MAAM,CAAC6C,iBAAiB,EAAE,UAACK,gBAAgB;IACnE,OAAOA,gBAAgB,CAACnJ,MAAM,GAAG,CAAC;EACpC,CAAC,CAAC;EAEF,IAAMoF,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACuJ,iBAAiB,EAAE,UAACE,cAAmB;IACxD,IAAMC,cAAc,GAAG1L,OAAA,CAAAgC,GAAG,CAACyJ,cAAc,EAAE,UAAC9J,QAAa;MACvD,OAAOA,QAAQ,CAAC0F,IAAI;IACtB,CAAC,CAAC;IAEF,IAAMsE,aAAa,GAAS3L,OAAA,CAAA4L,KAAK,CAACH,cAAc,CAAE,CAACtL,OAAO;IAC1D,OAAO;MACL0I,OAAO,EACL,+BAA6B8C,aAAa,OAAI,IAC9C,wDAAsDD,cAAc,CAACG,IAAI,CACvE,IAAI,CACL,QAAK;MACR/C,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAAC+C,wBAAwB;MACvDjL,UAAU,EAAE4K;KACb;EACH,CAAC,CAAC;EAEF,OAAOhE,MAAM;AACf;AAjDArH,OAAA,CAAAsI,qBAAA,GAAAA,qBAAA;AAmDA,SAAgBR,oBAAoBA,CAClCrH,UAAuB;EAEvB,IAAMkL,YAAY,GAAG/L,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAAC0C,KAAU;IACjD,IAAI,CAACvD,OAAA,CAAA4C,GAAG,CAACW,KAAK,EAAE,OAAO,CAAC,EAAE;MACxB,OAAO,KAAK;;IAEd,IAAMkC,KAAK,GAAGlC,KAAK,CAACE,KAAK;IAEzB,OAAOgC,KAAK,KAAK1F,cAAA,CAAA6B,KAAK,CAAC8B,OAAO,IAAI+B,KAAK,KAAK1F,cAAA,CAAA6B,KAAK,CAACC,EAAE,IAAI,CAAC7B,OAAA,CAAA4D,QAAQ,CAAC6B,KAAK,CAAC;EAC1E,CAAC,CAAC;EAEF,IAAMgC,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAAC+J,YAAY,EAAE,UAACpK,QAAQ;IACxC,OAAO;MACLkH,OAAO,EACL,gBAAgB,GAChBlH,QAAQ,CAAC0F,IAAI,GACb,+DAA+D;MACjEyB,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACiD,wBAAwB;MACvDnL,UAAU,EAAE,CAACc,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO8F,MAAM;AACf;AAxBArH,OAAA,CAAA8H,oBAAA,GAAAA,oBAAA;AA0BA,SAAgBC,uBAAuBA,CACrCtH,UAAuB,EACvBoL,UAAoB;EAEpB,IAAMC,YAAY,GAAGlM,OAAA,CAAAsI,MAAM,CAACzH,UAAU,EAAE,UAAC0C,KAAU;IACjD,OACEA,KAAK,CAACW,SAAS,KAAKP,SAAS,IAAI,CAAC3D,OAAA,CAAAuC,QAAQ,CAAC0J,UAAU,EAAE1I,KAAK,CAACW,SAAS,CAAC;EAE3E,CAAC,CAAC;EAEF,IAAMuD,MAAM,GAAGzH,OAAA,CAAAgC,GAAG,CAACkK,YAAY,EAAE,UAAC5H,OAAO;IACvC,IAAMhD,GAAG,GACP,mBAAiBgD,OAAO,CAAC+C,IAAI,mEAA8D/C,OAAO,CAACJ,SAAS,OAAI,GAChH,sBAAsB;IACxB,OAAO;MACL2E,OAAO,EAAEvH,GAAG;MACZwH,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACoD,wBAAwB;MACvDtL,UAAU,EAAE,CAACyD,OAAO;KACrB;EACH,CAAC,CAAC;EAEF,OAAOmD,MAAM;AACf;AAtBArH,OAAA,CAAA+H,uBAAA,GAAAA,uBAAA;AAwBA,SAAgBC,uBAAuBA,CACrCvH,UAAuB;EAEvB,IAAM4G,MAAM,GAAG,EAAE;EAEjB,IAAM2E,WAAW,GAAGpM,OAAA,CAAAgF,MAAM,CACxBnE,UAAU,EACV,UAACkF,MAAM,EAAEzB,OAAO,EAAEa,GAAG;IACnB,IAAMC,OAAO,GAAGd,OAAO,CAACnE,OAAO;IAE/B,IAAIiF,OAAO,KAAKrF,cAAA,CAAA6B,KAAK,CAACC,EAAE,EAAE;MACxB,OAAOkE,MAAM;;IAGf;IACA;IACA,IAAI/F,OAAA,CAAA4D,QAAQ,CAACwB,OAAO,CAAC,EAAE;MACrBW,MAAM,CAACL,IAAI,CAAC;QAAE2G,GAAG,EAAEjH,OAAO;QAAED,GAAG,EAAAA,GAAA;QAAES,SAAS,EAAEtB;MAAO,CAAE,CAAC;KACvD,MAAM,IAAItE,OAAA,CAAAkC,QAAQ,CAACkD,OAAO,CAAC,IAAIkH,UAAU,CAAClH,OAAO,CAAC,EAAE;MACnDW,MAAM,CAACL,IAAI,CAAC;QAAE2G,GAAG,EAAEjH,OAAO,CAAChD,MAAM;QAAE+C,GAAG,EAAAA,GAAA;QAAES,SAAS,EAAEtB;MAAO,CAAE,CAAC;;IAE/D,OAAOyB,MAAM;EACf,CAAC,EACD,EAAE,CACH;EAED/F,OAAA,CAAAyG,OAAO,CAAC5F,UAAU,EAAE,UAACyD,OAAO,EAAEiI,OAAO;IACnCvM,OAAA,CAAAyG,OAAO,CAAC2F,WAAW,EAAE,UAACI,EAAuB;UAArBH,GAAG,GAAAG,EAAA,CAAAH,GAAA;QAAElH,GAAG,GAAAqH,EAAA,CAAArH,GAAA;QAAES,SAAS,GAAA4G,EAAA,CAAA5G,SAAA;MACzC,IAAI2G,OAAO,GAAGpH,GAAG,IAAIsH,aAAa,CAACJ,GAAG,EAAE/H,OAAO,CAACnE,OAAO,CAAC,EAAE;QACxD,IAAMmB,GAAG,GACP,cAAYsE,SAAS,CAACyB,IAAI,+BAA4B,IACtD,+CAA6C/C,OAAO,CAAC+C,IAAI,OAAI,IAC7D,8BAA8B,GAC9B,8EAA8E;QAChFI,MAAM,CAAC/B,IAAI,CAAC;UACVmD,OAAO,EAAEvH,GAAG;UACZwH,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAAC2D,mBAAmB;UAClD7L,UAAU,EAAE,CAACyD,OAAO,EAAEsB,SAAS;SAChC,CAAC;;IAEN,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,OAAO6B,MAAM;AACf;AA5CArH,OAAA,CAAAgI,uBAAA,GAAAA,uBAAA;AA8CA,SAASqE,aAAaA,CAACJ,GAAW,EAAEjH,OAAY;EAC9C;EACA,IAAIpF,OAAA,CAAAkC,QAAQ,CAACkD,OAAO,CAAC,EAAE;IACrB,IAAMuH,WAAW,GAAGvH,OAAO,CAACzC,IAAI,CAAC0J,GAAG,CAAC;IACrC,OAAOM,WAAW,KAAK,IAAI,IAAIA,WAAW,CAACC,KAAK,KAAK,CAAC;GACvD,MAAM,IAAI5M,OAAA,CAAA0C,UAAU,CAAC0C,OAAO,CAAC,EAAE;IAC9B;IACA,OAAOA,OAAO,CAACiH,GAAG,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC;GAC/B,MAAM,IAAIrM,OAAA,CAAA4C,GAAG,CAACwC,OAAO,EAAE,MAAM,CAAC,EAAE;IAC/B;IACA,OAAOA,OAAO,CAACzC,IAAI,CAAC0J,GAAG,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC;GACpC,MAAM,IAAI,OAAOjH,OAAO,KAAK,QAAQ,EAAE;IACtC,OAAOA,OAAO,KAAKiH,GAAG;GACvB,MAAM;IACL,MAAMrJ,KAAK,CAAC,sBAAsB,CAAC;;AAEvC;AAEA,SAASsJ,UAAUA,CAACO,MAAc;EAChC;EACA,IAAMC,SAAS,GAAG,CAChB,GAAG,EACH,IAAI,EACJ,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,CACJ;EACD,OACE9M,OAAA,CAAA+M,IAAI,CAACD,SAAS,EAAE,UAACE,IAAI;IAAK,OAAAH,MAAM,CAACzK,MAAM,CAAC6B,OAAO,CAAC+I,IAAI,CAAC,KAAK,CAAC,CAAC;EAAlC,CAAkC,CAAC,KAAKrJ,SAAS;AAE/E;AAEA,SAAgBlB,eAAeA,CAAC2C,OAAe;EAC7C,IAAM6H,KAAK,GAAG7H,OAAO,CAAC9C,UAAU,GAAG,GAAG,GAAG,EAAE;EAC3C;EACA;EACA,OAAO,IAAI9B,MAAM,CAAC,SAAO4E,OAAO,CAAChD,MAAM,MAAG,EAAE6K,KAAK,CAAC;AACpD;AALA7M,OAAA,CAAAqC,eAAA,GAAAA,eAAA;AAOA,SAAgBD,aAAaA,CAAC4C,OAAe;EAC3C,IAAM6H,KAAK,GAAG7H,OAAO,CAAC9C,UAAU,GAAG,IAAI,GAAG,GAAG;EAC7C;EACA;EACA,OAAO,IAAI9B,MAAM,CAAC,KAAG4E,OAAO,CAAChD,MAAQ,EAAE6K,KAAK,CAAC;AAC/C;AALA7M,OAAA,CAAAoC,aAAA,GAAAA,aAAA;AAOA,SAAgB0K,oBAAoBA,CAClCC,eAA0C,EAC1CC,UAAmB,EACnBhM,wBAA6C;EAE7C,IAAMqG,MAAM,GAAG,EAAE;EAEjB;EACA,IAAI,CAACzH,OAAA,CAAA4C,GAAG,CAACuK,eAAe,EAAE/M,OAAA,CAAAC,YAAY,CAAC,EAAE;IACvCoH,MAAM,CAAC/B,IAAI,CAAC;MACVmD,OAAO,EACL,qDAAqD,GACrDzI,OAAA,CAAAC,YAAY,GACZ,gCAAgC;MAClCyI,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACsE;KAChC,CAAC;;EAEJ,IAAI,CAACrN,OAAA,CAAA4C,GAAG,CAACuK,eAAe,EAAE/M,OAAA,CAAAE,KAAK,CAAC,EAAE;IAChCmH,MAAM,CAAC/B,IAAI,CAAC;MACVmD,OAAO,EACL,qDAAqD,GACrDzI,OAAA,CAAAE,KAAK,GACL,gCAAgC;MAClCwI,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAACuE;KAChC,CAAC;;EAGJ,IACEtN,OAAA,CAAA4C,GAAG,CAACuK,eAAe,EAAE/M,OAAA,CAAAE,KAAK,CAAC,IAC3BN,OAAA,CAAA4C,GAAG,CAACuK,eAAe,EAAE/M,OAAA,CAAAC,YAAY,CAAC,IAClC,CAACL,OAAA,CAAA4C,GAAG,CAACuK,eAAe,CAACI,KAAK,EAAEJ,eAAe,CAACK,WAAW,CAAC,EACxD;IACA/F,MAAM,CAAC/B,IAAI,CAAC;MACVmD,OAAO,EACL,oDAAkDzI,OAAA,CAAAC,YAAY,WAAM8M,eAAe,CAACK,WAAW,MAAG,GAClG,wBAAwB;MAC1B1E,IAAI,EACF/I,cAAA,CAAAgJ,wBAAwB,CAAC0E;KAC5B,CAAC;;EAGJ,IAAIzN,OAAA,CAAA4C,GAAG,CAACuK,eAAe,EAAE/M,OAAA,CAAAE,KAAK,CAAC,EAAE;IAC/BN,OAAA,CAAAyG,OAAO,CAAC0G,eAAe,CAACI,KAAK,EAAE,UAACG,aAAa,EAAEC,YAAY;MACzD3N,OAAA,CAAAyG,OAAO,CAACiH,aAAa,EAAE,UAAC1H,WAAW,EAAE4H,OAAO;QAC1C,IAAI5N,OAAA,CAAA6D,WAAW,CAACmC,WAAW,CAAC,EAAE;UAC5ByB,MAAM,CAAC/B,IAAI,CAAC;YACVmD,OAAO,EACL,oEAAoE,IACpE,MAAI8E,YAAY,qBAAgBC,OAAO,QAAK;YAC9C9E,IAAI,EACF/I,cAAA,CAAAgJ,wBAAwB,CAAC8E;WAC5B,CAAC;;MAEN,CAAC,CAAC;IACJ,CAAC,CAAC;;EAGJ,OAAOpG,MAAM;AACf;AA1DArH,OAAA,CAAA8M,oBAAA,GAAAA,oBAAA;AA4DA,SAAgBY,2BAA2BA,CACzCX,eAA0C,EAC1CC,UAAmB,EACnBhM,wBAA6C;EAE7C,IAAM2M,QAAQ,GAAG,EAAE;EACnB,IAAIC,eAAe,GAAG,KAAK;EAC3B,IAAMC,aAAa,GAAGjO,OAAA,CAAAsL,OAAO,CAC3BtL,OAAA,CAAAkO,OAAO,CAAClO,OAAA,CAAAmO,SAAS,CAAChB,eAAe,CAACI,KAAK,EAAE,UAACa,QAAQ;IAAK,OAAAA,QAAQ;EAAR,CAAQ,CAAC,CAAC,CAClE;EAED,IAAMC,kBAAkB,GAAGrO,OAAA,CAAA0B,MAAM,CAC/BuM,aAAa,EACb,UAACtM,QAAQ;IAAK,OAAAA,QAAQ,CAACxB,OAAO,CAAC,KAAKJ,cAAA,CAAA6B,KAAK,CAACC,EAAE;EAA9B,CAA8B,CAC7C;EACD,IAAMyM,mBAAmB,GAAGjK,YAAY,CAACjD,wBAAwB,CAAC;EAClE,IAAIgM,UAAU,EAAE;IACdpN,OAAA,CAAAyG,OAAO,CAAC4H,kBAAkB,EAAE,UAAC/J,OAAO;MAClC,IAAMiK,SAAS,GAAG/J,qBAAqB,CAACF,OAAO,EAAEgK,mBAAmB,CAAC;MACrE,IAAIC,SAAS,KAAK,KAAK,EAAE;QACvB,IAAM1F,OAAO,GAAG2F,0BAA0B,CAAClK,OAAO,EAAEiK,SAAS,CAAC;QAC9D,IAAME,iBAAiB,GAAG;UACxB5F,OAAO,EAAAA,OAAA;UACPC,IAAI,EAAEyF,SAAS,CAACG,KAAK;UACrB9I,SAAS,EAAEtB;SACZ;QACDyJ,QAAQ,CAACrI,IAAI,CAAC+I,iBAAiB,CAAC;OACjC,MAAM;QACL;QACA,IAAIzO,OAAA,CAAA4C,GAAG,CAAC0B,OAAO,EAAE,aAAa,CAAC,EAAE;UAC/B,IAAIA,OAAO,CAACC,WAAW,KAAK,IAAI,EAAE;YAChCyJ,eAAe,GAAG,IAAI;;SAEzB,MAAM;UACL,IAAI/N,SAAA,CAAAwE,gBAAgB,CAAC6J,mBAAmB,EAAEhK,OAAO,CAACnE,OAAO,CAAC,EAAE;YAC1D6N,eAAe,GAAG,IAAI;;;;IAI9B,CAAC,CAAC;;EAGJ,IAAIZ,UAAU,IAAI,CAACY,eAAe,EAAE;IAClCD,QAAQ,CAACrI,IAAI,CAAC;MACZmD,OAAO,EACL,kCAAkC,GAClC,uEAAuE,GACvE,kFAAkF,GAClF,mFAAmF,GACnF,gBAAgB;MAClBC,IAAI,EAAE/I,cAAA,CAAAgJ,wBAAwB,CAAC4F;KAChC,CAAC;;EAEJ,OAAOZ,QAAQ;AACjB;AAtDA3N,OAAA,CAAA0N,2BAAA,GAAAA,2BAAA;AAwDA,SAAgBc,gBAAgBA,CAAChK,WAEhC;EACC,IAAMiK,YAAY,GAAQ,EAAE;EAC5B,IAAMC,SAAS,GAAG9O,OAAA,CAAA+O,IAAI,CAACnK,WAAW,CAAC;EAEnC5E,OAAA,CAAAyG,OAAO,CAACqI,SAAS,EAAE,UAACE,OAAO;IACzB,IAAMC,cAAc,GAAGrK,WAAW,CAACoK,OAAO,CAAC;IAE3C;IACA,IAAIhP,OAAA,CAAAsG,OAAO,CAAC2I,cAAc,CAAC,EAAE;MAC3BJ,YAAY,CAACG,OAAO,CAAC,GAAG,EAAE;KAC3B,MAAM;MACL,MAAMhM,KAAK,CAAC,sBAAsB,CAAC;;EAEvC,CAAC,CAAC;EAEF,OAAO6L,YAAY;AACrB;AAlBAzO,OAAA,CAAAwO,gBAAA,GAAAA,gBAAA;AAoBA;AACA,SAAgB9J,eAAeA,CAACc,SAAc;EAC5C,IAAMR,OAAO,GAAGQ,SAAS,CAACzF,OAAO;EACjC;EACA,IAAIH,OAAA,CAAAkC,QAAQ,CAACkD,OAAO,CAAC,EAAE;IACrB,OAAO,KAAK;GACb,MAAM,IAAIpF,OAAA,CAAA0C,UAAU,CAAC0C,OAAO,CAAC,EAAE;IAC9B;IACA,OAAO,IAAI;GACZ,MAAM,IAAIpF,OAAA,CAAA4C,GAAG,CAACwC,OAAO,EAAE,MAAM,CAAC,EAAE;IAC/B;IACA,OAAO,IAAI;GACZ,MAAM,IAAIpF,OAAA,CAAA4D,QAAQ,CAACwB,OAAO,CAAC,EAAE;IAC5B,OAAO,KAAK;GACb,MAAM;IACL,MAAMpC,KAAK,CAAC,sBAAsB,CAAC;;AAEvC;AAhBA5C,OAAA,CAAA0E,eAAA,GAAAA,eAAA;AAkBA,SAAgBC,cAAcA,CAACK,OAAY;EACzC,IAAIpF,OAAA,CAAA4D,QAAQ,CAACwB,OAAO,CAAC,IAAIA,OAAO,CAAC/C,MAAM,KAAK,CAAC,EAAE;IAC7C,OAAO+C,OAAO,CAACc,UAAU,CAAC,CAAC,CAAC;GAC7B,MAAM;IACL,OAAO,KAAK;;AAEhB;AANA9F,OAAA,CAAA2E,cAAA,GAAAA,cAAA;AAQA;;;AAGa3E,OAAA,CAAA8O,6BAA6B,GAA2B;EACnE;EACA5E,IAAI,EAAE,SAAAA,CAAU6E,IAAI;IAClB,IAAMC,GAAG,GAAGD,IAAI,CAAC9M,MAAM;IACvB,KAAK,IAAIgN,CAAC,GAAG,IAAI,CAACC,SAAS,EAAED,CAAC,GAAGD,GAAG,EAAEC,CAAC,EAAE,EAAE;MACzC,IAAME,CAAC,GAAGJ,IAAI,CAACjJ,UAAU,CAACmJ,CAAC,CAAC;MAC5B,IAAIE,CAAC,KAAK,EAAE,EAAE;QACZ,IAAI,CAACD,SAAS,GAAGD,CAAC,GAAG,CAAC;QACtB,OAAO,IAAI;OACZ,MAAM,IAAIE,CAAC,KAAK,EAAE,EAAE;QACnB,IAAIJ,IAAI,CAACjJ,UAAU,CAACmJ,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,EAAE;UACjC,IAAI,CAACC,SAAS,GAAGD,CAAC,GAAG,CAAC;SACvB,MAAM;UACL,IAAI,CAACC,SAAS,GAAGD,CAAC,GAAG,CAAC;;QAExB,OAAO,IAAI;;;IAGf,OAAO,KAAK;EACd,CAAC;EAEDC,SAAS,EAAE;CACZ;AAED,SAAS9K,qBAAqBA,CAC5BF,OAAkB,EAClBF,uBAAiC;EASjC,IAAIpE,OAAA,CAAA4C,GAAG,CAAC0B,OAAO,EAAE,aAAa,CAAC,EAAE;IAC/B;IACA;IACA,OAAO,KAAK;GACb,MAAM;IACL;IACA,IAAItE,OAAA,CAAAkC,QAAQ,CAACoC,OAAO,CAACnE,OAAO,CAAC,EAAE;MAC7B,IAAI;QACF;QACAF,SAAA,CAAAwE,gBAAgB,CAACL,uBAAuB,EAAEE,OAAO,CAACnE,OAAiB,CAAC;OACrE,CAAC,OAAOkK,CAAC,EAAE;QACV;QACA,OAAO;UACLqE,KAAK,EAAE3O,cAAA,CAAAgJ,wBAAwB,CAACyG,mBAAmB;UACnDC,MAAM,EAAEpF,CAAC,CAACxB;SACX;;MAEH,OAAO,KAAK;KACb,MAAM,IAAI7I,OAAA,CAAA4D,QAAQ,CAACU,OAAO,CAACnE,OAAO,CAAC,EAAE;MACpC;MACA,OAAO,KAAK;KACb,MAAM,IAAI2E,eAAe,CAACR,OAAO,CAAC,EAAE;MACnC;MACA,OAAO;QAAEoK,KAAK,EAAE3O,cAAA,CAAAgJ,wBAAwB,CAAC2G;MAAiB,CAAE;KAC7D,MAAM;MACL,MAAM1M,KAAK,CAAC,sBAAsB,CAAC;;;AAGzC;AAEA,SAAgBwL,0BAA0BA,CACxClK,OAAkB,EAClBqL,OAKC;EAED;EACA,IAAIA,OAAO,CAACjB,KAAK,KAAK3O,cAAA,CAAAgJ,wBAAwB,CAACyG,mBAAmB,EAAE;IAClE,OACE,iEAAiE,IACjE,8BAA4BlL,OAAO,CAAC+C,IAAI,mBAAgB,KACxD,oBAAkBsI,OAAO,CAACF,MAAM,QAAK,IACrC,qGAAqG;GAExG,MAAM,IAAIE,OAAO,CAACjB,KAAK,KAAK3O,cAAA,CAAAgJ,wBAAwB,CAAC2G,iBAAiB,EAAE;IACvE,OACE,4EAA4E,IAC5E,8BAA4BpL,OAAO,CAAC+C,IAAI,mBAAgB,IACxD,mGAAmG;GAEtG,MAAM;IACL,MAAMrE,KAAK,CAAC,sBAAsB,CAAC;;AAEvC;AA1BA5C,OAAA,CAAAoO,0BAAA,GAAAA,0BAAA;AA4BA,SAASnK,YAAYA,CAACuL,YAAiC;EACrD,IAAMC,SAAS,GAAG7P,OAAA,CAAAgC,GAAG,CAAC4N,YAAY,EAAE,UAACE,WAAW;IAC9C,IAAI9P,OAAA,CAAA4D,QAAQ,CAACkM,WAAW,CAAC,IAAIA,WAAW,CAACzN,MAAM,GAAG,CAAC,EAAE;MACnD,OAAOyN,WAAW,CAAC5J,UAAU,CAAC,CAAC,CAAC;KACjC,MAAM;MACL,OAAO4J,WAAW;;EAEtB,CAAC,CAAC;EAEF,OAAOD,SAAS;AAClB;AAEA,SAASxJ,gBAAgBA,CAACrE,GAAG,EAAE+N,GAAG,EAAEC,KAAK;EACvC,IAAIhO,GAAG,CAAC+N,GAAG,CAAC,KAAKpM,SAAS,EAAE;IAC1B3B,GAAG,CAAC+N,GAAG,CAAC,GAAG,CAACC,KAAK,CAAC;GACnB,MAAM;IACLhO,GAAG,CAAC+N,GAAG,CAAC,CAACrK,IAAI,CAACsK,KAAK,CAAC;;AAExB;AAEa5P,OAAA,CAAA6P,kBAAkB,GAAG,GAAG;AAErC;;;;;;;;;;;;;;;AAeA,IAAIC,yBAAyB,GAAG,EAAE;AAClC,SAAgB9J,wBAAwBA,CAACH,QAAQ;EAC/C,OAAOA,QAAQ,GAAG7F,OAAA,CAAA6P,kBAAkB,GAChChK,QAAQ,GACRiK,yBAAyB,CAACjK,QAAQ,CAAC;AACzC;AAJA7F,OAAA,CAAAgG,wBAAA,GAAAA,wBAAA;AAMA;;;;;;;;AAQA,SAAS5E,+BAA+BA,CAAA;EACtC,IAAIxB,OAAA,CAAAmH,OAAO,CAAC+I,yBAAyB,CAAC,EAAE;IACtCA,yBAAyB,GAAG,IAAIC,KAAK,CAAC,KAAK,CAAC;IAC5C,KAAK,IAAId,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,KAAK,EAAEA,CAAC,EAAE,EAAE;MAC9B;MACAa,yBAAyB,CAACb,CAAC,CAAC,GAAGA,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,CAAC,EAAEA,CAAC,GAAG,GAAG,CAAC,GAAGA,CAAC;MAC9D;;;AAGN"},"metadata":{},"sourceType":"script","externalDependencies":[]}