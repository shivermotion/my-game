{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.tokenMatcher = exports.createTokenInstance = exports.EOF = exports.createToken = exports.hasTokenLabel = exports.tokenName = exports.tokenLabel = void 0;\nvar utils_1 = require(\"@chevrotain/utils\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar tokens_1 = require(\"./tokens\");\nfunction tokenLabel(tokType) {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\nexports.tokenLabel = tokenLabel;\nfunction tokenName(tokType) {\n  return tokType.name;\n}\nexports.tokenName = tokenName;\nfunction hasTokenLabel(obj) {\n  return utils_1.isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nexports.hasTokenLabel = hasTokenLabel;\nvar PARENT = \"parent\";\nvar CATEGORIES = \"categories\";\nvar LABEL = \"label\";\nvar GROUP = \"group\";\nvar PUSH_MODE = \"push_mode\";\nvar POP_MODE = \"pop_mode\";\nvar LONGER_ALT = \"longer_alt\";\nvar LINE_BREAKS = \"line_breaks\";\nvar START_CHARS_HINT = \"start_chars_hint\";\nfunction createToken(config) {\n  return createTokenInternal(config);\n}\nexports.createToken = createToken;\nfunction createTokenInternal(config) {\n  var pattern = config.pattern;\n  var tokenType = {};\n  tokenType.name = config.name;\n  if (!utils_1.isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n  if (utils_1.has(config, PARENT)) {\n    throw \"The parent property is no longer supported.\\n\" + \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\";\n  }\n  if (utils_1.has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = config[CATEGORIES];\n  }\n  tokens_1.augmentTokenTypes([tokenType]);\n  if (utils_1.has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n  if (utils_1.has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n  if (utils_1.has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n  if (utils_1.has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n  if (utils_1.has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n  if (utils_1.has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n  if (utils_1.has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n  return tokenType;\n}\nexports.EOF = createToken({\n  name: \"EOF\",\n  pattern: lexer_public_1.Lexer.NA\n});\ntokens_1.augmentTokenTypes([exports.EOF]);\nfunction createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n  return {\n    image: image,\n    startOffset: startOffset,\n    endOffset: endOffset,\n    startLine: startLine,\n    endLine: endLine,\n    startColumn: startColumn,\n    endColumn: endColumn,\n    tokenTypeIdx: tokType.tokenTypeIdx,\n    tokenType: tokType\n  };\n}\nexports.createTokenInstance = createTokenInstance;\nfunction tokenMatcher(token, tokType) {\n  return tokens_1.tokenStructuredMatcher(token, tokType);\n}\nexports.tokenMatcher = tokenMatcher;","map":{"version":3,"names":["utils_1","require","lexer_public_1","tokens_1","tokenLabel","tokType","hasTokenLabel","LABEL","name","exports","tokenName","obj","isString","PARENT","CATEGORIES","GROUP","PUSH_MODE","POP_MODE","LONGER_ALT","LINE_BREAKS","START_CHARS_HINT","createToken","config","createTokenInternal","pattern","tokenType","isUndefined","PATTERN","has","augmentTokenTypes","EOF","Lexer","NA","createTokenInstance","image","startOffset","endOffset","startLine","endLine","startColumn","endColumn","tokenTypeIdx","tokenMatcher","token","tokenStructuredMatcher"],"sources":["C:\\Users\\Work\\node_modules\\chevrotain\\src\\scan\\tokens_public.ts"],"sourcesContent":["import { has, isString, isUndefined } from \"@chevrotain/utils\"\nimport { Lexer } from \"./lexer_public\"\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens\"\nimport { IToken, ITokenConfig, TokenType } from \"@chevrotain/types\"\n\nexport function tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL\n  } else {\n    return tokType.name\n  }\n}\n\nexport function tokenName(tokType: TokenType): string {\n  return tokType.name\n}\n\nexport function hasTokenLabel(obj: TokenType): boolean {\n  return isString((<any>obj).LABEL) && (<any>obj).LABEL !== \"\"\n}\n\nconst PARENT = \"parent\"\nconst CATEGORIES = \"categories\"\nconst LABEL = \"label\"\nconst GROUP = \"group\"\nconst PUSH_MODE = \"push_mode\"\nconst POP_MODE = \"pop_mode\"\nconst LONGER_ALT = \"longer_alt\"\nconst LINE_BREAKS = \"line_breaks\"\nconst START_CHARS_HINT = \"start_chars_hint\"\n\nexport function createToken(config: ITokenConfig): TokenType {\n  return createTokenInternal(config)\n}\n\nfunction createTokenInternal(config: ITokenConfig): TokenType {\n  const pattern = config.pattern\n\n  const tokenType: TokenType = <any>{}\n  tokenType.name = config.name\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern\n  }\n\n  if (has(config, PARENT)) {\n    throw (\n      \"The parent property is no longer supported.\\n\" +\n      \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\"\n    )\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = <any>config[CATEGORIES]\n  }\n\n  augmentTokenTypes([tokenType])\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL]\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP]\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE]\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE]\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT]\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS]\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT]\n  }\n\n  return tokenType\n}\n\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA })\naugmentTokenTypes([EOF])\n\nexport function createTokenInstance(\n  tokType: TokenType,\n  image: string,\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number\n): IToken {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: (<any>tokType).tokenTypeIdx,\n    tokenType: tokType\n  }\n}\n\nexport function tokenMatcher(token: IToken, tokType: TokenType): boolean {\n  return tokenStructuredMatcher(token, tokType)\n}\n"],"mappings":";;;;;;AAAA,IAAAA,OAAA,GAAAC,OAAA;AACA,IAAAC,cAAA,GAAAD,OAAA;AACA,IAAAE,QAAA,GAAAF,OAAA;AAGA,SAAgBG,UAAUA,CAACC,OAAkB;EAC3C,IAAIC,aAAa,CAACD,OAAO,CAAC,EAAE;IAC1B,OAAOA,OAAO,CAACE,KAAK;GACrB,MAAM;IACL,OAAOF,OAAO,CAACG,IAAI;;AAEvB;AANAC,OAAA,CAAAL,UAAA,GAAAA,UAAA;AAQA,SAAgBM,SAASA,CAACL,OAAkB;EAC1C,OAAOA,OAAO,CAACG,IAAI;AACrB;AAFAC,OAAA,CAAAC,SAAA,GAAAA,SAAA;AAIA,SAAgBJ,aAAaA,CAACK,GAAc;EAC1C,OAAOX,OAAA,CAAAY,QAAQ,CAAOD,GAAI,CAACJ,KAAK,CAAC,IAAUI,GAAI,CAACJ,KAAK,KAAK,EAAE;AAC9D;AAFAE,OAAA,CAAAH,aAAA,GAAAA,aAAA;AAIA,IAAMO,MAAM,GAAG,QAAQ;AACvB,IAAMC,UAAU,GAAG,YAAY;AAC/B,IAAMP,KAAK,GAAG,OAAO;AACrB,IAAMQ,KAAK,GAAG,OAAO;AACrB,IAAMC,SAAS,GAAG,WAAW;AAC7B,IAAMC,QAAQ,GAAG,UAAU;AAC3B,IAAMC,UAAU,GAAG,YAAY;AAC/B,IAAMC,WAAW,GAAG,aAAa;AACjC,IAAMC,gBAAgB,GAAG,kBAAkB;AAE3C,SAAgBC,WAAWA,CAACC,MAAoB;EAC9C,OAAOC,mBAAmB,CAACD,MAAM,CAAC;AACpC;AAFAb,OAAA,CAAAY,WAAA,GAAAA,WAAA;AAIA,SAASE,mBAAmBA,CAACD,MAAoB;EAC/C,IAAME,OAAO,GAAGF,MAAM,CAACE,OAAO;EAE9B,IAAMC,SAAS,GAAmB,EAAE;EACpCA,SAAS,CAACjB,IAAI,GAAGc,MAAM,CAACd,IAAI;EAE5B,IAAI,CAACR,OAAA,CAAA0B,WAAW,CAACF,OAAO,CAAC,EAAE;IACzBC,SAAS,CAACE,OAAO,GAAGH,OAAO;;EAG7B,IAAIxB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAET,MAAM,CAAC,EAAE;IACvB,MACE,+CAA+C,GAC/C,8FAA8F;;EAIlG,IAAIb,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAER,UAAU,CAAC,EAAE;IAC3B;IACAW,SAAS,CAACX,UAAU,GAAQQ,MAAM,CAACR,UAAU,CAAC;;EAGhDX,QAAA,CAAA0B,iBAAiB,CAAC,CAACJ,SAAS,CAAC,CAAC;EAE9B,IAAIzB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEf,KAAK,CAAC,EAAE;IACtBkB,SAAS,CAAClB,KAAK,GAAGe,MAAM,CAACf,KAAK,CAAC;;EAGjC,IAAIP,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEP,KAAK,CAAC,EAAE;IACtBU,SAAS,CAACV,KAAK,GAAGO,MAAM,CAACP,KAAK,CAAC;;EAGjC,IAAIf,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEL,QAAQ,CAAC,EAAE;IACzBQ,SAAS,CAACR,QAAQ,GAAGK,MAAM,CAACL,QAAQ,CAAC;;EAGvC,IAAIjB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEN,SAAS,CAAC,EAAE;IAC1BS,SAAS,CAACT,SAAS,GAAGM,MAAM,CAACN,SAAS,CAAC;;EAGzC,IAAIhB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEJ,UAAU,CAAC,EAAE;IAC3BO,SAAS,CAACP,UAAU,GAAGI,MAAM,CAACJ,UAAU,CAAC;;EAG3C,IAAIlB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEH,WAAW,CAAC,EAAE;IAC5BM,SAAS,CAACN,WAAW,GAAGG,MAAM,CAACH,WAAW,CAAC;;EAG7C,IAAInB,OAAA,CAAA4B,GAAG,CAACN,MAAM,EAAEF,gBAAgB,CAAC,EAAE;IACjCK,SAAS,CAACL,gBAAgB,GAAGE,MAAM,CAACF,gBAAgB,CAAC;;EAGvD,OAAOK,SAAS;AAClB;AAEahB,OAAA,CAAAqB,GAAG,GAAGT,WAAW,CAAC;EAAEb,IAAI,EAAE,KAAK;EAAEgB,OAAO,EAAEtB,cAAA,CAAA6B,KAAK,CAACC;AAAE,CAAE,CAAC;AAClE7B,QAAA,CAAA0B,iBAAiB,CAAC,CAACpB,OAAA,CAAAqB,GAAG,CAAC,CAAC;AAExB,SAAgBG,mBAAmBA,CACjC5B,OAAkB,EAClB6B,KAAa,EACbC,WAAmB,EACnBC,SAAiB,EACjBC,SAAiB,EACjBC,OAAe,EACfC,WAAmB,EACnBC,SAAiB;EAEjB,OAAO;IACLN,KAAK,EAAAA,KAAA;IACLC,WAAW,EAAAA,WAAA;IACXC,SAAS,EAAAA,SAAA;IACTC,SAAS,EAAAA,SAAA;IACTC,OAAO,EAAAA,OAAA;IACPC,WAAW,EAAAA,WAAA;IACXC,SAAS,EAAAA,SAAA;IACTC,YAAY,EAAQpC,OAAQ,CAACoC,YAAY;IACzChB,SAAS,EAAEpB;GACZ;AACH;AArBAI,OAAA,CAAAwB,mBAAA,GAAAA,mBAAA;AAuBA,SAAgBS,YAAYA,CAACC,KAAa,EAAEtC,OAAkB;EAC5D,OAAOF,QAAA,CAAAyC,sBAAsB,CAACD,KAAK,EAAEtC,OAAO,CAAC;AAC/C;AAFAI,OAAA,CAAAiC,YAAA,GAAAA,YAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}